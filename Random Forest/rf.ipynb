{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d2ed239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory: d:\\DSS5104\\data\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import psutil\n",
    "import threading\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, roc_auc_score,\n",
    "    mean_squared_error, mean_absolute_error, r2_score\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from dataloader import load_data\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d93ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tabular_data(X_df, y, cat_cols, cont_cols, is_train=False, scaler=None, encoder=None):\n",
    "    X = X_df.copy()\n",
    "\n",
    "    if cat_cols:\n",
    "        X[cat_cols] = X[cat_cols].astype(str)\n",
    "\n",
    "        if is_train:\n",
    "            encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "            X[cat_cols] = encoder.fit_transform(X[cat_cols])\n",
    "        else:\n",
    "            X[cat_cols] = encoder.transform(X[cat_cols])\n",
    "    else:\n",
    "        encoder = None\n",
    "\n",
    "    if cont_cols:\n",
    "        X[cont_cols] = X[cont_cols].astype(\"float32\")\n",
    "        if is_train:\n",
    "            scaler = StandardScaler()\n",
    "            X[cont_cols] = scaler.fit_transform(X[cont_cols])\n",
    "        else:\n",
    "            X[cont_cols] = scaler.transform(X[cont_cols])\n",
    "    else:\n",
    "        scaler = None\n",
    "\n",
    "    return X, np.array(y), scaler, encoder\n",
    "\n",
    "\n",
    "def prepare_data_np(dataset_name: str):\n",
    "    dataset_name = dataset_name.lower()\n",
    "\n",
    "    if dataset_name.startswith(\"adult\"):\n",
    "        '''\n",
    "        you can select a seed:777, 888, 999, \n",
    "        and change the seed 'build_model(task_type: str, seed = 999)' at the same time\n",
    "        '''\n",
    "        data_train, data_test = load_data(\"adult\", seed = 999) \n",
    "        X_train, y_train = data_train.drop(columns=['income']), (data_train['income'] == '>50K').astype(int)\n",
    "        X_val, y_val = data_test.drop(columns=['income']), (data_test['income'] == '>50K').astype(int)\n",
    "        task_type = \"classification\"\n",
    "\n",
    "    elif dataset_name.startswith(\"california\"):\n",
    "        X_train, X_val, y_train, y_val = load_data(\"california\", seed = 777)\n",
    "        task_type = \"regression\"\n",
    "\n",
    "    elif dataset_name.startswith(\"higgs\"):\n",
    "        X_train, X_val, y_train, y_val = load_data(\"higgs\")\n",
    "        y_train, y_val = (y_train == 1).astype(int), (y_val == 1).astype(int)\n",
    "        task_type = \"classification\"\n",
    "\n",
    "    elif dataset_name.startswith(\"churn\"):\n",
    "        X_train, X_val, y_train, y_val = load_data(\"churn\")\n",
    "        y_train, y_val = (y_train == 'Yes').astype(int), (y_val == 'Yes').astype(int)\n",
    "        task_type = \"classification\"\n",
    "\n",
    "    elif dataset_name.startswith(\"creditcard\"):\n",
    "        X_train, X_val, y_train, y_val = load_data(\"credit\")\n",
    "        y_train, y_val = (y_train == 1).astype(int), (y_val == 1).astype(int)\n",
    "        task_type = \"classification\"\n",
    "\n",
    "    elif dataset_name.startswith(\"poker\"):\n",
    "        X_train, X_val, y_train, y_val = load_data(\"poker\")\n",
    "        task_type = \"classification\"\n",
    "\n",
    "    elif dataset_name.startswith(\"bank\"):\n",
    "        X_train, X_val, y_train, y_val = load_data(\"bank\")\n",
    "        y_train, y_val = (y_train == 'yes').astype(int), (y_val == 'yes').astype(int)\n",
    "        task_type = \"classification\"\n",
    "\n",
    "    elif dataset_name.startswith(\"wine\"):\n",
    "        X_train, X_val, y_train, y_val = load_data(\"wine\")\n",
    "        task_type = \"regression\"\n",
    "\n",
    "    elif dataset_name.startswith(\"covtype\"):\n",
    "        X_train, X_val, y_train, y_val = load_data(\"covtype\")\n",
    "        task_type = \"classification\"\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported dataset: {dataset_name}\")\n",
    "\n",
    "    cat_cols = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    cont_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "    X_train_processed, y_train_array, scaler, encoder = preprocess_tabular_data(\n",
    "        X_train, y_train, cat_cols, cont_cols, is_train=True)\n",
    "\n",
    "    X_val_processed, y_val_array, _, _ = preprocess_tabular_data(\n",
    "        X_val, y_val, cat_cols, cont_cols, is_train=False, scaler=scaler, encoder=encoder)\n",
    "\n",
    "    return (X_train_processed, y_train_array), (X_val_processed, y_val_array), task_type\n",
    "\n",
    "\n",
    "def build_model(task_type: str, seed = 999):\n",
    "    if task_type == \"classification\":\n",
    "        model = RandomForestClassifier(n_estimators=100, max_depth=None, random_state=seed, n_jobs=-1)\n",
    "    elif task_type == \"regression\":\n",
    "        model = RandomForestRegressor(n_estimators=100, max_depth=None, random_state=seed, n_jobs=-1)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported task type: {task_type}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, task_type, train_time, avg_cpu_usage):\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    results = {\n",
    "        \"train_time_seconds\": round(train_time, 4),\n",
    "        \"cpu_usage\": round(avg_cpu_usage, 4)\n",
    "    }\n",
    "\n",
    "    print(\"\\nEvaluation Results:\")\n",
    "\n",
    "    if task_type == \"classification\":\n",
    "        acc = accuracy_score(y_test, y_test_pred)\n",
    "        f1 = f1_score(y_test, y_test_pred, average='macro')\n",
    "        results.update({\n",
    "            \"test_accuracy\": round(acc, 4),\n",
    "            \"test_f1\": round(f1, 4),\n",
    "        })\n",
    "        \n",
    "        print(f\"Accuracy: {acc:.4f}\")\n",
    "        print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "        try:\n",
    "            y_proba = model.predict_proba(X_test)\n",
    "            auc = roc_auc_score(y_test, y_proba[:, 1])\n",
    "            results[\"test_auc\"] = round(auc, 4)\n",
    "            print(f\"AUC: {auc:.4f}\")\n",
    "        except Exception as e:\n",
    "            results[\"test_auc\"] = np.nan\n",
    "            print(\"AUC can't be calculated:\", e)\n",
    "\n",
    "    else:  # regression\n",
    "        rmse = mean_squared_error(y_test, y_test_pred) ** 0.5\n",
    "        mae = mean_absolute_error(y_test, y_test_pred)\n",
    "        r2 = r2_score(y_test, y_test_pred)\n",
    "        results.update({\n",
    "            \"test_rmse\": round(rmse, 4),\n",
    "            \"test_mae\": round(mae, 4),\n",
    "            \"test_r2\": round(r2, 4),\n",
    "        })\n",
    "        \n",
    "        print(f\"RMSE: {rmse:.4f}\")\n",
    "        print(f\"MAE: {mae:.4f}\")\n",
    "        print(f\"R²: {r2:.4f}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def monitor_cpu(interval, usage_list, stop_flag):\n",
    "    psutil.cpu_percent(interval=None) \n",
    "    while not stop_flag.is_set():\n",
    "        usage = psutil.cpu_percent(interval=interval) \n",
    "        usage_list.append(usage)\n",
    "\n",
    "def run_xgboost_pipeline(dataset_name):\n",
    "    (X_train, y_train), (X_val, y_val), task_type = prepare_data_np(dataset_name)\n",
    "    model = build_model(task_type)\n",
    "\n",
    "    cpu_usages = []\n",
    "    stop_flag = threading.Event()\n",
    "    monitor_thread = threading.Thread(target=monitor_cpu, args=(0.1, cpu_usages, stop_flag))\n",
    "\n",
    "    start_time = time.time()\n",
    "    monitor_thread.start()\n",
    "    time.sleep(0.1) \n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    stop_flag.set()\n",
    "    monitor_thread.join()\n",
    "    train_time = time.time() - start_time\n",
    "\n",
    "    avg_cpu_usage = sum(cpu_usages) / len(cpu_usages) if cpu_usages else 0\n",
    "\n",
    "    results = evaluate_model(model, X_val, y_val, task_type, train_time, avg_cpu_usage)\n",
    "    return model, results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aaf08f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeding: 999\n",
      "binary classification\n",
      "(30162, 15) (30162,)\n",
      "(15060, 15) (15060,)\n",
      "\n",
      "Evaluation Results:\n",
      "Accuracy: 0.8491\n",
      "F1 Score: 0.7845\n",
      "AUC: 0.9030\n",
      "\n",
      "Final Metrics Summary:\n",
      "train_time_seconds: 1.1723\n",
      "cpu_usage: 82.8091\n",
      "test_accuracy: 0.8491\n",
      "test_f1: 0.7845\n",
      "test_auc: 0.903\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"adult\"  \n",
    "_, metrics = run_xgboost_pipeline(dataset_name)\n",
    "print(\"\\nFinal Metrics Summary:\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b2c47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeding: 888\n",
      "binary classification\n",
      "(30162, 15) (30162,)\n",
      "(15060, 15) (15060,)\n",
      "\n",
      "Evaluation Results:\n",
      "Accuracy: 0.8509\n",
      "F1 Score: 0.7871\n",
      "AUC: 0.9025\n",
      "\n",
      "Final Metrics Summary:\n",
      "train_time_seconds: 1.039\n",
      "cpu_usage: 80.52\n",
      "test_accuracy: 0.8509\n",
      "test_f1: 0.7871\n",
      "test_auc: 0.9025\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"adult\"  \n",
    "_, metrics = run_xgboost_pipeline(dataset_name)\n",
    "print(\"\\nFinal Metrics Summary:\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728766af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeding: 777\n",
      "binary classification\n",
      "(30162, 15) (30162,)\n",
      "(15060, 15) (15060,)\n",
      "\n",
      "Evaluation Results:\n",
      "Accuracy: 0.8515\n",
      "F1 Score: 0.7880\n",
      "AUC: 0.9020\n",
      "\n",
      "Final Metrics Summary:\n",
      "train_time_seconds: 1.0606\n",
      "cpu_usage: 73.17\n",
      "test_accuracy: 0.8515\n",
      "test_f1: 0.788\n",
      "test_auc: 0.902\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"adult\"  \n",
    "_, metrics = run_xgboost_pipeline(dataset_name)\n",
    "print(\"\\nFinal Metrics Summary:\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0551a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeding: 999\n",
      "binary classification\n",
      "(32950, 20) (32950,)\n",
      "(8238, 20) (8238,)\n",
      "\n",
      "Evaluation Results:\n",
      "Accuracy: 0.9201\n",
      "F1 Score: 0.7787\n",
      "AUC: 0.9489\n",
      "\n",
      "Final Metrics Summary:\n",
      "train_time_seconds: 1.1207\n",
      "cpu_usage: 83.01\n",
      "test_accuracy: 0.9201\n",
      "test_f1: 0.7787\n",
      "test_auc: 0.9489\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"bank+marketing\"  \n",
    "_, metrics = run_xgboost_pipeline(dataset_name)\n",
    "print(\"\\nFinal Metrics Summary:\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d2ddc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeding: 999\n",
      "multi-class classification\n",
      "(464809, 12) (464809,)\n",
      "(116203, 12) (116203,)\n",
      "\n",
      "Evaluation Results:\n",
      "Accuracy: 0.9648\n",
      "F1 Score: 0.9392\n",
      "AUC can't be calculated: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "Final Metrics Summary:\n",
      "train_time_seconds: 69.6606\n",
      "cpu_usage: 98.6259\n",
      "test_accuracy: 0.9648\n",
      "test_f1: 0.9392\n",
      "test_auc: nan\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"covtype\"  \n",
    "_, metrics = run_xgboost_pipeline(dataset_name)\n",
    "print(\"\\nFinal Metrics Summary:\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e462ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeding: 999\n",
      "multi-class classification\n",
      "(25010, 10) (25010,)\n",
      "(1000000, 10) (1000000,)\n",
      "\n",
      "Evaluation Results:\n",
      "Accuracy: 0.6115\n",
      "F1 Score: 0.1759\n",
      "AUC can't be calculated: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "Final Metrics Summary:\n",
      "train_time_seconds: 1.2795\n",
      "cpu_usage: 73.8333\n",
      "test_accuracy: 0.6115\n",
      "test_f1: 0.1759\n",
      "test_auc: nan\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"poker\"  \n",
    "_, metrics = run_xgboost_pipeline(dataset_name)\n",
    "print(\"\\nFinal Metrics Summary:\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0698a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeding: 999\n",
      "multi-class classification\n",
      "(2558, 11) (2558,)\n",
      "(640, 11) (640,)\n",
      "\n",
      "Evaluation Results:\n",
      "RMSE: 0.2896\n",
      "MAE: 0.1843\n",
      "R²: 0.8710\n",
      "\n",
      "Final Metrics Summary:\n",
      "train_time_seconds: 0.5358\n",
      "cpu_usage: 67.16\n",
      "test_rmse: 0.2896\n",
      "test_mae: 0.1843\n",
      "test_r2: 0.871\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"wine\"  \n",
    "_, metrics = run_xgboost_pipeline(dataset_name)\n",
    "print(\"\\nFinal Metrics Summary:\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401b143c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeding: 999\n",
      "regression\n",
      "(16512, 8) (16512,)\n",
      "(4128, 8) (4128,)\n",
      "\n",
      "Evaluation Results:\n",
      "RMSE: 0.5117\n",
      "MAE: 0.3307\n",
      "R²: 0.8126\n",
      "\n",
      "Final Metrics Summary:\n",
      "train_time_seconds: 3.2111\n",
      "cpu_usage: 92.9846\n",
      "test_rmse: 0.5117\n",
      "test_mae: 0.3307\n",
      "test_r2: 0.8126\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"california\"  \n",
    "_, metrics = run_xgboost_pipeline(dataset_name)\n",
    "print(\"\\nFinal Metrics Summary:\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f81f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeding: 888\n",
      "regression\n",
      "(16512, 8) (16512,)\n",
      "(4128, 8) (4128,)\n",
      "\n",
      "Evaluation Results:\n",
      "RMSE: 0.5149\n",
      "MAE: 0.3318\n",
      "R²: 0.7966\n",
      "\n",
      "Final Metrics Summary:\n",
      "train_time_seconds: 3.505\n",
      "cpu_usage: 93.8852\n",
      "test_rmse: 0.5149\n",
      "test_mae: 0.3318\n",
      "test_r2: 0.7966\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"california\"  \n",
    "_, metrics = run_xgboost_pipeline(dataset_name)\n",
    "print(\"\\nFinal Metrics Summary:\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd496539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeding: 777\n",
      "regression\n",
      "(16512, 8) (16512,)\n",
      "(4128, 8) (4128,)\n",
      "\n",
      "Evaluation Results:\n",
      "RMSE: 0.4994\n",
      "MAE: 0.3204\n",
      "R²: 0.8065\n",
      "\n",
      "Final Metrics Summary:\n",
      "train_time_seconds: 3.3156\n",
      "cpu_usage: 90.1462\n",
      "test_rmse: 0.4994\n",
      "test_mae: 0.3204\n",
      "test_r2: 0.8065\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"california\"  \n",
    "_, metrics = run_xgboost_pipeline(dataset_name)\n",
    "print(\"\\nFinal Metrics Summary:\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ef4554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeding: 999\n",
      "binary classification\n",
      "(227845, 30) (227845,)\n",
      "(56962, 30) (56962,)\n",
      "\n",
      "Evaluation Results:\n",
      "Accuracy: 0.9996\n",
      "F1 Score: 0.9325\n",
      "AUC: 0.9630\n",
      "\n",
      "Final Metrics Summary:\n",
      "train_time_seconds: 72.3207\n",
      "cpu_usage: 97.544\n",
      "test_accuracy: 0.9996\n",
      "test_f1: 0.9325\n",
      "test_auc: 0.963\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"creditcard\"  \n",
    "_, metrics = run_xgboost_pipeline(dataset_name)\n",
    "print(\"\\nFinal Metrics Summary:\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1179890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeding: 999\n",
      "binary classification\n",
      "(5625, 19) (5625,)\n",
      "(1407, 19) (1407,)\n",
      "\n",
      "Evaluation Results:\n",
      "Accuracy: 0.7946\n",
      "F1 Score: 0.7149\n",
      "AUC: 0.8179\n",
      "\n",
      "Final Metrics Summary:\n",
      "train_time_seconds: 0.4158\n",
      "cpu_usage: 60.65\n",
      "test_accuracy: 0.7946\n",
      "test_f1: 0.7149\n",
      "test_auc: 0.8179\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"churn\"  \n",
    "_, metrics = run_xgboost_pipeline(dataset_name)\n",
    "print(\"\\nFinal Metrics Summary:\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
