{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d2ed239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory: d:\\DSS5104\\data\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import psutil\n",
    "import threading\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, roc_auc_score,\n",
    "    mean_squared_error, mean_absolute_error, r2_score\n",
    ")\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from dataloader import load_data\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d93ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tabular_data(X_df, y, cat_cols, cont_cols, is_train=False, scaler=None, encoder=None):\n",
    "    X = X_df.copy()\n",
    "\n",
    "    if cat_cols:\n",
    "        X[cat_cols] = X[cat_cols].astype(str)\n",
    "\n",
    "        if is_train:\n",
    "            encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "            X[cat_cols] = encoder.fit_transform(X[cat_cols])\n",
    "        else:\n",
    "            X[cat_cols] = encoder.transform(X[cat_cols])\n",
    "    else:\n",
    "        encoder = None\n",
    "\n",
    "    if cont_cols:\n",
    "        X[cont_cols] = X[cont_cols].astype(\"float32\")\n",
    "        if is_train:\n",
    "            scaler = StandardScaler()\n",
    "            X[cont_cols] = scaler.fit_transform(X[cont_cols])\n",
    "        else:\n",
    "            X[cont_cols] = scaler.transform(X[cont_cols])\n",
    "    else:\n",
    "        scaler = None\n",
    "\n",
    "    return X, np.array(y), scaler, encoder\n",
    "\n",
    "\n",
    "def prepare_data_np(dataset_name: str):\n",
    "    dataset_name = dataset_name.lower()\n",
    "\n",
    "    if dataset_name.startswith(\"adult\"):\n",
    "        '''\n",
    "        you can select a seed:777, 888, 999, \n",
    "        and change the seed 'build_model(task_type: str, seed = 999)' at the same time\n",
    "        '''\n",
    "        data_train, data_test = load_data(\"adult\", seed = 777)\n",
    "        X_train, y_train = data_train.drop(columns=['income']), (data_train['income'] == '>50K').astype(int)\n",
    "        X_val, y_val = data_test.drop(columns=['income']), (data_test['income'] == '>50K').astype(int)\n",
    "        task_type = \"classification\"\n",
    "\n",
    "    elif dataset_name.startswith(\"california\"):\n",
    "        X_train, X_val, y_train, y_val = load_data(\"california\", seed = 777)\n",
    "        task_type = \"regression\"\n",
    "\n",
    "    elif dataset_name.startswith(\"higgs\"):\n",
    "        X_train, X_val, y_train, y_val = load_data(\"higgs\")\n",
    "        y_train, y_val = (y_train == 1).astype(int), (y_val == 1).astype(int)\n",
    "        task_type = \"classification\"\n",
    "\n",
    "    elif dataset_name.startswith(\"churn\"):\n",
    "        X_train, X_val, y_train, y_val = load_data(\"churn\")\n",
    "        y_train, y_val = (y_train == 'Yes').astype(int), (y_val == 'Yes').astype(int)\n",
    "        task_type = \"classification\"\n",
    "\n",
    "    elif dataset_name.startswith(\"creditcard\"):\n",
    "        X_train, X_val, y_train, y_val = load_data(\"credit\")\n",
    "        y_train, y_val = (y_train == 1).astype(int), (y_val == 1).astype(int)\n",
    "        task_type = \"classification\"\n",
    "\n",
    "    elif dataset_name.startswith(\"poker\"):\n",
    "        X_train, X_val, y_train, y_val = load_data(\"poker\")\n",
    "        task_type = \"classification\"\n",
    "\n",
    "    elif dataset_name.startswith(\"bank\"):\n",
    "        X_train, X_val, y_train, y_val = load_data(\"bank\")\n",
    "        y_train, y_val = (y_train == 'yes').astype(int), (y_val == 'yes').astype(int)\n",
    "        task_type = \"classification\"\n",
    "\n",
    "    elif dataset_name.startswith(\"wine\"):\n",
    "        X_train, X_val, y_train, y_val = load_data(\"wine\")\n",
    "        task_type = \"regression\"\n",
    "\n",
    "    elif dataset_name.startswith(\"covtype\"):\n",
    "        X_train, X_val, y_train, y_val = load_data(\"covtype\")\n",
    "        task_type = \"classification\"\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported dataset: {dataset_name}\")\n",
    "\n",
    "    cat_cols = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    cont_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "    X_train_processed, y_train_array, scaler, encoder = preprocess_tabular_data(\n",
    "        X_train, y_train, cat_cols, cont_cols, is_train=True)\n",
    "\n",
    "    X_val_processed, y_val_array, _, _ = preprocess_tabular_data(\n",
    "        X_val, y_val, cat_cols, cont_cols, is_train=False, scaler=scaler, encoder=encoder)\n",
    "\n",
    "    return (X_train_processed, y_train_array), (X_val_processed, y_val_array), task_type\n",
    "\n",
    "\n",
    "def build_model(task_type: str, seed=999):\n",
    "    if task_type == \"classification\":\n",
    "        model = XGBClassifier(\n",
    "            n_jobs=-1,\n",
    "            random_state=seed,\n",
    "            sub_sample=0.8,\n",
    "            use_label_encoder=False,\n",
    "            eval_metric='logloss'\n",
    "        )\n",
    "    elif task_type == \"regression\":\n",
    "        model = XGBRegressor(\n",
    "            n_jobs=-1,\n",
    "            random_state=seed\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported task type: {task_type}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, task_type, train_time, avg_cpu_usage):\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    results = {\n",
    "        \"train_time_seconds\": round(train_time, 4),\n",
    "        \"cpu_usage\": round(avg_cpu_usage, 4)\n",
    "    }\n",
    "\n",
    "    print(\"\\nEvaluation Results:\")\n",
    "\n",
    "    if task_type == \"classification\":\n",
    "        acc = accuracy_score(y_test, y_test_pred)\n",
    "        f1 = f1_score(y_test, y_test_pred, average='macro')\n",
    "        results.update({\n",
    "            \"test_accuracy\": round(acc, 4),\n",
    "            \"test_f1\": round(f1, 4),\n",
    "        })\n",
    "        \n",
    "        print(f\"Accuracy: {acc:.4f}\")\n",
    "        print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "        try:\n",
    "            y_proba = model.predict_proba(X_test)\n",
    "            auc = roc_auc_score(y_test, y_proba[:, 1])\n",
    "            results[\"test_auc\"] = round(auc, 4)\n",
    "            print(f\"AUC: {auc:.4f}\")\n",
    "        except Exception as e:\n",
    "            results[\"test_auc\"] = np.nan\n",
    "            print(\"AUC can't be calculated:\", e)\n",
    "\n",
    "    else:  # regression\n",
    "        rmse = mean_squared_error(y_test, y_test_pred) ** 0.5\n",
    "        mae = mean_absolute_error(y_test, y_test_pred)\n",
    "        r2 = r2_score(y_test, y_test_pred)\n",
    "        results.update({\n",
    "            \"test_rmse\": round(rmse, 4),\n",
    "            \"test_mae\": round(mae, 4),\n",
    "            \"test_r2\": round(r2, 4),\n",
    "        })\n",
    "        \n",
    "        print(f\"RMSE: {rmse:.4f}\")\n",
    "        print(f\"MAE: {mae:.4f}\")\n",
    "        print(f\"R²: {r2:.4f}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def monitor_cpu(interval, usage_list, stop_flag):\n",
    "    psutil.cpu_percent(interval=None) \n",
    "    while not stop_flag.is_set():\n",
    "        usage = psutil.cpu_percent(interval=interval) \n",
    "        usage_list.append(usage)\n",
    "\n",
    "def run_xgboost_pipeline(dataset_name):\n",
    "    (X_train, y_train), (X_val, y_val), task_type = prepare_data_np(dataset_name)\n",
    "    model = build_model(task_type)\n",
    "\n",
    "    cpu_usages = []\n",
    "    stop_flag = threading.Event()\n",
    "    monitor_thread = threading.Thread(target=monitor_cpu, args=(0.1, cpu_usages, stop_flag))\n",
    "\n",
    "    start_time = time.time()\n",
    "    monitor_thread.start()\n",
    "    time.sleep(0.1) \n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    stop_flag.set()\n",
    "    monitor_thread.join()\n",
    "    train_time = time.time() - start_time\n",
    "\n",
    "    avg_cpu_usage = sum(cpu_usages) / len(cpu_usages) if cpu_usages else 0\n",
    "\n",
    "    results = evaluate_model(model, X_val, y_val, task_type, train_time, avg_cpu_usage)\n",
    "    return model, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aaf08f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeding: 999\n",
      "binary classification\n",
      "(30162, 15) (30162,)\n",
      "(15060, 15) (15060,)\n",
      "\n",
      "Evaluation Results:\n",
      "Accuracy: 0.8655\n",
      "F1 Score: 0.8099\n",
      "AUC: 0.9244\n",
      "\n",
      "Final Metrics Summary:\n",
      "train_time_seconds: 0.3035\n",
      "cpu_usage: 67.8333\n",
      "test_accuracy: 0.8655\n",
      "test_f1: 0.8099\n",
      "test_auc: 0.9244\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"adult\"  \n",
    "_, metrics = run_xgboost_pipeline(dataset_name)\n",
    "print(\"\\nFinal Metrics Summary:\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af11b1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeding: 888\n",
      "binary classification\n",
      "(30162, 15) (30162,)\n",
      "(15060, 15) (15060,)\n",
      "\n",
      "Evaluation Results:\n",
      "Accuracy: 0.8655\n",
      "F1 Score: 0.8099\n",
      "AUC: 0.9244\n",
      "\n",
      "Final Metrics Summary:\n",
      "train_time_seconds: 0.3051\n",
      "cpu_usage: 67.9\n",
      "test_accuracy: 0.8655\n",
      "test_f1: 0.8099\n",
      "test_auc: 0.9244\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"adult\"  \n",
    "_, metrics = run_xgboost_pipeline(dataset_name)\n",
    "print(\"\\nFinal Metrics Summary:\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275baac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeding: 777\n",
      "binary classification\n",
      "(30162, 15) (30162,)\n",
      "(15060, 15) (15060,)\n",
      "\n",
      "Evaluation Results:\n",
      "Accuracy: 0.8655\n",
      "F1 Score: 0.8099\n",
      "AUC: 0.9244\n",
      "\n",
      "Final Metrics Summary:\n",
      "train_time_seconds: 0.3166\n",
      "cpu_usage: 73.1333\n",
      "test_accuracy: 0.8655\n",
      "test_f1: 0.8099\n",
      "test_auc: 0.9244\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"adult\"  \n",
    "_, metrics = run_xgboost_pipeline(dataset_name)\n",
    "print(\"\\nFinal Metrics Summary:\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0551a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeding: 999\n",
      "binary classification\n",
      "(32950, 20) (32950,)\n",
      "(8238, 20) (8238,)\n",
      "\n",
      "Evaluation Results:\n",
      "Accuracy: 0.9176\n",
      "F1 Score: 0.7732\n",
      "AUC: 0.9509\n",
      "\n",
      "Final Metrics Summary:\n",
      "train_time_seconds: 0.3037\n",
      "cpu_usage: 68.0667\n",
      "test_accuracy: 0.9176\n",
      "test_f1: 0.7732\n",
      "test_auc: 0.9509\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"bank+marketing\"  \n",
    "_, metrics = run_xgboost_pipeline(dataset_name)\n",
    "print(\"\\nFinal Metrics Summary:\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d2ddc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeding: 999\n",
      "multi-class classification\n",
      "(464809, 12) (464809,)\n",
      "(116203, 12) (116203,)\n",
      "\n",
      "Evaluation Results:\n",
      "Accuracy: 0.8746\n",
      "F1 Score: 0.8635\n",
      "AUC can't be calculated: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "Final Metrics Summary:\n",
      "train_time_seconds: 23.398\n",
      "cpu_usage: 99.5549\n",
      "test_accuracy: 0.8746\n",
      "test_f1: 0.8635\n",
      "test_auc: nan\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"covtype\"  \n",
    "_, metrics = run_xgboost_pipeline(dataset_name)\n",
    "print(\"\\nFinal Metrics Summary:\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69861a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeding: 999\n",
      "multi-class classification\n",
      "(46480, 12) (46480,)\n",
      "(11621, 12) (11621,)\n",
      "\n",
      "Evaluation Results:\n",
      "Accuracy: 0.8485\n",
      "F1 Score: 0.7983\n",
      "AUC can't be calculated: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "Final Metrics Summary:\n",
      "train_time_seconds: 1.7298\n",
      "cpu_usage: 91.9588\n",
      "test_accuracy: 0.8485\n",
      "test_f1: 0.7983\n",
      "test_auc: nan\n"
     ]
    }
   ],
   "source": [
    "#frac = 0.1--change the dataloader.py to load the data with frac = 0.1\n",
    "dataset_name = \"covtype\"  \n",
    "_, metrics = run_xgboost_pipeline(dataset_name)\n",
    "print(\"\\nFinal Metrics Summary:\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc5a706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeding: 999\n",
      "multi-class classification\n",
      "(232404, 12) (232404,)\n",
      "(58102, 12) (58102,)\n",
      "\n",
      "Evaluation Results:\n",
      "Accuracy: 0.8722\n",
      "F1 Score: 0.8516\n",
      "AUC can't be calculated: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "Final Metrics Summary:\n",
      "train_time_seconds: 10.2125\n",
      "cpu_usage: 98.9303\n",
      "test_accuracy: 0.8722\n",
      "test_f1: 0.8516\n",
      "test_auc: nan\n"
     ]
    }
   ],
   "source": [
    "#frac = 0.5\n",
    "dataset_name = \"covtype\"  \n",
    "_, metrics = run_xgboost_pipeline(dataset_name)\n",
    "print(\"\\nFinal Metrics Summary:\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e462ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeding: 999\n",
      "multi-class classification\n",
      "(25010, 10) (25010,)\n",
      "(1000000, 10) (1000000,)\n",
      "\n",
      "Evaluation Results:\n",
      "Accuracy: 0.7401\n",
      "F1 Score: 0.1856\n",
      "AUC can't be calculated: multi_class must be in ('ovo', 'ovr')\n",
      "\n",
      "Final Metrics Summary:\n",
      "train_time_seconds: 1.5242\n",
      "cpu_usage: 93.4533\n",
      "test_accuracy: 0.7401\n",
      "test_f1: 0.1856\n",
      "test_auc: nan\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"poker\"  \n",
    "_, metrics = run_xgboost_pipeline(dataset_name)\n",
    "print(\"\\nFinal Metrics Summary:\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0698a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeding: 999\n",
      "multi-class classification\n",
      "(2558, 11) (2558,)\n",
      "(640, 11) (640,)\n",
      "\n",
      "Evaluation Results:\n",
      "RMSE: 0.2111\n",
      "MAE: 0.1055\n",
      "R²: 0.9315\n",
      "\n",
      "Final Metrics Summary:\n",
      "train_time_seconds: 0.3482\n",
      "cpu_usage: 61.4333\n",
      "test_rmse: 0.2111\n",
      "test_mae: 0.1055\n",
      "test_r2: 0.9315\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"wine\"  \n",
    "_, metrics = run_xgboost_pipeline(dataset_name)\n",
    "print(\"\\nFinal Metrics Summary:\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401b143c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeding: 999\n",
      "regression\n",
      "(16512, 8) (16512,)\n",
      "(4128, 8) (4128,)\n",
      "\n",
      "Evaluation Results:\n",
      "RMSE: 0.4737\n",
      "MAE: 0.3121\n",
      "R²: 0.8394\n",
      "\n",
      "Final Metrics Summary:\n",
      "train_time_seconds: 0.4422\n",
      "cpu_usage: 84.2\n",
      "test_rmse: 0.4737\n",
      "test_mae: 0.3121\n",
      "test_r2: 0.8394\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"california\"  \n",
    "_, metrics = run_xgboost_pipeline(dataset_name)\n",
    "print(\"\\nFinal Metrics Summary:\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377ed1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeding: 888\n",
      "regression\n",
      "(16512, 8) (16512,)\n",
      "(4128, 8) (4128,)\n",
      "\n",
      "Evaluation Results:\n",
      "RMSE: 0.4747\n",
      "MAE: 0.3087\n",
      "R²: 0.8271\n",
      "\n",
      "Final Metrics Summary:\n",
      "train_time_seconds: 0.4079\n",
      "cpu_usage: 74.575\n",
      "test_rmse: 0.4747\n",
      "test_mae: 0.3087\n",
      "test_r2: 0.8271\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"california\"  \n",
    "_, metrics = run_xgboost_pipeline(dataset_name)\n",
    "print(\"\\nFinal Metrics Summary:\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25e5ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeding: 777\n",
      "regression\n",
      "(16512, 8) (16512,)\n",
      "(4128, 8) (4128,)\n",
      "\n",
      "Evaluation Results:\n",
      "RMSE: 0.4698\n",
      "MAE: 0.3061\n",
      "R²: 0.8288\n",
      "\n",
      "Final Metrics Summary:\n",
      "train_time_seconds: 0.3044\n",
      "cpu_usage: 86.3667\n",
      "test_rmse: 0.4698\n",
      "test_mae: 0.3061\n",
      "test_r2: 0.8288\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"california\"  \n",
    "_, metrics = run_xgboost_pipeline(dataset_name)\n",
    "print(\"\\nFinal Metrics Summary:\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ef4554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeding: 999\n",
      "binary classification\n",
      "(227845, 30) (227845,)\n",
      "(56962, 30) (56962,)\n",
      "\n",
      "Evaluation Results:\n",
      "Accuracy: 0.9992\n",
      "F1 Score: 0.8789\n",
      "AUC: 0.8773\n",
      "\n",
      "Final Metrics Summary:\n",
      "train_time_seconds: 2.0961\n",
      "cpu_usage: 93.61\n",
      "test_accuracy: 0.9992\n",
      "test_f1: 0.8789\n",
      "test_auc: 0.8773\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"creditcard\"  \n",
    "_, metrics = run_xgboost_pipeline(dataset_name)\n",
    "print(\"\\nFinal Metrics Summary:\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3c500e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeding: 999\n",
      "binary classification\n",
      "(5625, 19) (5625,)\n",
      "(1407, 19) (1407,)\n",
      "\n",
      "Evaluation Results:\n",
      "Accuracy: 0.7825\n",
      "F1 Score: 0.7062\n",
      "AUC: 0.8184\n",
      "\n",
      "Final Metrics Summary:\n",
      "train_time_seconds: 0.3046\n",
      "cpu_usage: 75.6\n",
      "test_accuracy: 0.7825\n",
      "test_f1: 0.7062\n",
      "test_auc: 0.8184\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"churn\"  \n",
    "_, metrics = run_xgboost_pipeline(dataset_name)\n",
    "print(\"\\nFinal Metrics Summary:\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
