{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af57fb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\")  # 忽略警告信息\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "import copy\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from rtdl_revisiting_models import FTTransformer\n",
    "\n",
    "warnings.resetwarnings()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import delu\n",
    "delu.random.seed(999)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4e45acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory: d:\\DSS5104\\data\n"
     ]
    }
   ],
   "source": [
    "from dataloader import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8477eafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_cont_features: int, cat_cardinalities: list, d_out: int):\n",
    "    \"\"\"\n",
    "    Build an FT-Transformer model.\n",
    "    n_cont_features: number of continuous (numeric) features\n",
    "    cat_cardinalities: list of cardinalities for each categorical feature (empty if none)\n",
    "    d_out: dimension of model output (e.g. number of classes or 1)\n",
    "    \"\"\"\n",
    "    model = FTTransformer(\n",
    "        n_cont_features=n_cont_features,\n",
    "        cat_cardinalities=cat_cardinalities,\n",
    "        d_out=d_out,\n",
    "        **FTTransformer.get_default_kwargs()  # use default recommended hyperparameters\n",
    "    ).to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0b5d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, X_df, y, cat_cols, cont_cols, task_type, is_train=False, scaler=None, cat_categories=None):\n",
    "\n",
    "        self.cat_cols = cat_cols\n",
    "        self.cont_cols = cont_cols\n",
    "        self.task_type = task_type\n",
    "\n",
    "        X = X_df.copy()\n",
    "        \n",
    "        # 类别型特征处理：转换为categorical类型并编码\n",
    "        self.cat_cardinalities = []      # 保存每个类别特征的基数（unique个数）\n",
    "        self.cat_categories = {}         # 保存训练集中每个类别特征的类别值列表\n",
    "        if self.cat_cols:\n",
    "            for col in self.cat_cols:\n",
    "                if is_train:\n",
    "                    # 训练集：将特征转换为categorical并获取类别列表\n",
    "                    X[col] = X[col].astype('category')\n",
    "                    self.cat_categories[col] = X[col].cat.categories  # 保存类别值\n",
    "                    self.cat_cardinalities.append(X[col].nunique())   # 唯一值数量作为类别基数\n",
    "                else:\n",
    "                    # 验证/测试集：若提供了训练集的类别列表，则使用它保证编码一致\n",
    "                    if cat_categories is not None and col in cat_categories:\n",
    "                        X[col] = pd.Categorical(X[col], categories=cat_categories[col])\n",
    "                    else:\n",
    "                        X[col] = X[col].astype('category')\n",
    "                # 将类别值映射为编码 (0,...,n-1)，缺失或未知类别将被编码为 -1\n",
    "                X[col] = X[col].cat.codes\n",
    "\n",
    "        \n",
    "        # 连续型特征处理：转换类型并标准化\n",
    "        self.scaler = None\n",
    "        if self.cont_cols:\n",
    "            # 确保连续特征为float32类型\n",
    "            X[self.cont_cols] = X[self.cont_cols].astype('float32')\n",
    "            if is_train:\n",
    "                # 拟合StandardScaler并应用于训练数据\n",
    "                self.scaler = StandardScaler()\n",
    "                X[self.cont_cols] = self.scaler.fit_transform(X[self.cont_cols])\n",
    "            else:\n",
    "                # 使用训练集的Scaler对验证/测试集进行变换\n",
    "                X[self.cont_cols] = scaler.transform(X[self.cont_cols])\n",
    "        \n",
    "        # 保存处理后的特征为Tensor\n",
    "        if self.cont_cols:\n",
    "            # 连续特征转换为浮点Tensor\n",
    "            self.X_cont = torch.tensor(X[self.cont_cols].values, dtype=torch.float32)\n",
    "        else:\n",
    "            # 若没有连续特征，则用None占位\n",
    "            self.X_cont = None\n",
    "        if self.cat_cols:\n",
    "            # 类别特征转换为长整型Tensor\n",
    "            self.X_cat = torch.tensor(X[self.cat_cols].values, dtype=torch.long)\n",
    "        else:\n",
    "            self.X_cat = None\n",
    "        \n",
    "        # 目标变量处理：根据任务类型选择dtype\n",
    "        # 对于分类任务，默认使用long张量存储类别（若二分类且使用BCELoss，后续会转换为float）\n",
    "        # 对于回归任务，使用float张量\n",
    "        y_array = np.array(y)  # 将Series转换为numpy数组\n",
    "        if task_type == \"classification\":\n",
    "            # 检查y的数据类型，若已经是浮点（表示二分类），则用float32，否则用long\n",
    "            target_dtype = torch.float32 if str(y_array.dtype).startswith('float') else torch.long\n",
    "            self.y = torch.tensor(y_array, dtype=target_dtype)\n",
    "        else:\n",
    "            self.y = torch.tensor(y_array, dtype=torch.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        # 返回数据集样本数量\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # 根据索引idx返回一个样本的特征和标签\n",
    "        # 提取连续特征，如果没有连续特征则返回空Tensor\n",
    "        x_cont = self.X_cont[idx] if self.X_cont is not None else None\n",
    "        # 提取类别特征，如果没有类别特征则返回None\n",
    "        x_cat = self.X_cat[idx] if self.X_cat is not None else None\n",
    "        y = self.y[idx]\n",
    "        return x_cont, x_cat, y\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Combine the list samples of a batch (batch) into one batch output.\n",
    "    The batch argument is a list containing a number of tuples (x_cont, x_cat, y) returned by __getitem__ from Dataset.\n",
    "    This function stacks these samples into a batch tensor and handles the None case.\n",
    "    \"\"\"\n",
    "    x_cont_list, x_cat_list, y_list = [], [], []\n",
    "    for (x_cont, x_cat, y) in batch:\n",
    "        # Add continuous features and labels to the list\n",
    "        if x_cont is not None:\n",
    "            x_cont_list.append(x_cont)\n",
    "        y_list.append(y)\n",
    "        # Add the category feature to the list (if it exists)\n",
    "        if x_cat is not None:\n",
    "            x_cat_list.append(x_cat)\n",
    "    # Stacking lists as tensor\n",
    "    x_cont_batch = torch.stack(x_cont_list) if len(x_cont_list) > 0 else None\n",
    "    y_batch = torch.stack(y_list)\n",
    "\n",
    "    if len(x_cat_list) > 0:\n",
    "        x_cat_batch = torch.stack(x_cat_list)\n",
    "    else:\n",
    "        x_cat_batch = None\n",
    "    return x_cont_batch, x_cat_batch, y_batch\n",
    "\n",
    "\n",
    "def prepare_data(dataset: str,batch_size: int = 256):   \n",
    "    dataset = dataset.lower()\n",
    "\n",
    "    if dataset.startswith(\"adult\"):\n",
    "        data_train, data_test = load_data(\"adult\")\n",
    "        X_train = data_train.drop(columns=['income'])\n",
    "        y_train = data_train['income']\n",
    "        X_val = data_test.drop(columns=['income'])\n",
    "        y_val = data_test['income']\n",
    "        y_train = (y_train == '>50K').astype(int)\n",
    "        y_val = (y_val == '>50K').astype(int)\n",
    "        task_type = \"classification\"\n",
    "        \n",
    "    elif dataset.startswith(\"california\"):\n",
    "        X_train, X_val, y_train, y_val = load_data(\"california\")\n",
    "        task_type = \"regression\"\n",
    "        \n",
    "    elif dataset.startswith(\"higgs\"):\n",
    "        X_train, X_val, y_train, y_val = load_data(\"higgs\")\n",
    "        y_train = (y_train == 1).astype(int)\n",
    "        y_val = (y_val == 1).astype(int)\n",
    "        task_type = \"classification\"\n",
    "        \n",
    "    elif dataset.startswith(\"churn\"):\n",
    "        X_train, X_val, y_train, y_val = load_data(\"churn\")\n",
    "        y_train = (y_train == 'Yes').astype(int)\n",
    "        y_val = (y_val == 'Yes').astype(int)\n",
    "        task_type = \"classification\"\n",
    "        \n",
    "    elif dataset.startswith(\"creditcard\"):\n",
    "        X_train, X_val, y_train, y_val = load_data(\"credit\")\n",
    "        y_train = (y_train == 1).astype(int)\n",
    "        y_val = (y_val == 1).astype(int)\n",
    "        task_type = \"classification\"\n",
    "        \n",
    "    elif dataset.startswith(\"poker\"):\n",
    "        X_train, X_val, y_train, y_val = load_data(\"poker\") \n",
    "        task_type = \"classification\" \n",
    "        \n",
    "    elif dataset.startswith(\"bank\"):\n",
    "        X_train, X_val, y_train, y_val = load_data(\"bank\")\n",
    "        y_train = (y_train == 'yes').astype(int)\n",
    "        y_val = (y_val == 'yes').astype(int)\n",
    "        task_type = \"classification\"\n",
    "        \n",
    "    elif dataset.startswith(\"wine\"):\n",
    "        X_train, X_val, y_train, y_val = load_data(\"wine\")\n",
    "        task_type = \"regression\"\n",
    "        \n",
    "    elif dataset.startswith(\"covtype\"):\n",
    "        X_train, X_val, y_train, y_val = load_data(\"covtype\")\n",
    "        task_type = \"classification\"\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported dataset: {dataset}\")\n",
    "    \n",
    "\n",
    "    cat_cols = X_train.select_dtypes(include=['category', 'object']).columns.tolist()\n",
    "    cont_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    \n",
    "\n",
    "    if task_type == \"classification\":\n",
    "        y_train = y_train.astype('int64')\n",
    "        y_val = y_val.astype('int64')\n",
    "\n",
    "        n_classes = pd.Series(y_train).nunique() \n",
    "        \n",
    "        d_out = 1 if n_classes == 2 else n_classes\n",
    "        \n",
    "        if d_out == 1:\n",
    "            y_train = y_train.astype('float32')\n",
    "            y_val = y_val.astype('float32')\n",
    "    else:\n",
    "        y_train = y_train.astype('float32')\n",
    "        y_val = y_val.astype('float32')\n",
    "        d_out = 1\n",
    "    \n",
    "\n",
    "    train_dataset = TabularDataset(X_train, y_train, cat_cols, cont_cols, task_type, is_train=True)\n",
    "    val_dataset = TabularDataset(X_val, y_val, cat_cols, cont_cols, task_type, is_train=False,\n",
    "                                 scaler=train_dataset.scaler, cat_categories=train_dataset.cat_categories)\n",
    "    \n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "    \n",
    "    n_cont_features = len(cont_cols)                          # Number of continuous features\n",
    "    cat_cardinalities = train_dataset.cat_cardinalities       # List of bases for each category of features\n",
    "    task_type = task_type\n",
    "    \n",
    "    data_loaders = {\"train\": train_loader, \"val\": val_loader}\n",
    "    return data_loaders, n_cont_features, cat_cardinalities, d_out, task_type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc505c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, task_type, d_out, \n",
    "                n_epochs=100, batch_size=256, patience=10, lr=3e-4, weight_decay=1e-5):\n",
    "\n",
    "    if task_type == \"classification\":\n",
    "        loss_fn = F.binary_cross_entropy_with_logits if d_out == 1 else F.cross_entropy\n",
    "    else:\n",
    "        loss_fn = F.mse_loss  \n",
    "    \n",
    "    # optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=0)\n",
    "    best_val_score = None\n",
    "    best_epoch = -1\n",
    "    best_state = None\n",
    "    patience_counter = 0\n",
    "\n",
    "    maximize_metric = True if task_type == \"classification\" else False\n",
    "    \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        for x_cont_batch, x_cat_batch, y_batch in train_loader:\n",
    "\n",
    "            x_cont_batch = x_cont_batch.to(device) if x_cont_batch is not None else None\n",
    "            x_cat_batch = x_cat_batch.to(device) if x_cat_batch is not None else None\n",
    "            y_batch = y_batch.to(device)\n",
    "  \n",
    "            logits = model(x_cont_batch, x_cat_batch) if x_cat_batch is not None else model(x_cont_batch, None)\n",
    "\n",
    "            if task_type == \"classification\" and d_out == 1:\n",
    "                logits = logits.squeeze(-1)  \n",
    "            elif task_type == \"regression\":\n",
    "                logits = logits.squeeze(-1)  \n",
    "\n",
    "            loss = loss_fn(logits, y_batch)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            batch_size_actual = y_batch.size(0)\n",
    "            total_loss += loss.item() * batch_size_actual\n",
    "            total_samples += batch_size_actual\n",
    "\n",
    "            if task_type == \"classification\":\n",
    "                if d_out == 1:\n",
    "                    preds = (logits > 0).long()\n",
    "                    targets = y_batch.long()  \n",
    "                else:\n",
    "                    preds = torch.argmax(logits, dim=1)\n",
    "                    targets = y_batch\n",
    "                total_correct += (preds == targets).sum().item()\n",
    "\n",
    "        avg_train_loss = total_loss / total_samples\n",
    "\n",
    "        train_acc = total_correct / total_samples if task_type == \"classification\" else None\n",
    "        \n",
    "        # Evaluate on a validation set\n",
    "        model.eval()\n",
    "        val_loss_total = 0.0\n",
    "        val_correct = 0\n",
    "        total_val_samples = 0\n",
    "        with torch.no_grad():\n",
    "            for x_cont_val, x_cat_val, y_val in val_loader:\n",
    "                x_cont_val = x_cont_val.to(device) if x_cont_val is not None else None\n",
    "                x_cat_val = x_cat_val.to(device) if x_cat_val is not None else None\n",
    "                y_val = y_val.to(device)\n",
    "   \n",
    "                val_logits = model(x_cont_val, x_cat_val) if x_cat_val is not None else model(x_cont_val, None)\n",
    "                if task_type == \"classification\" and d_out == 1:\n",
    "                    val_logits = val_logits.squeeze(-1)\n",
    "                elif task_type == \"regression\":\n",
    "                    val_logits = val_logits.squeeze(-1)\n",
    "\n",
    "                val_loss = loss_fn(val_logits, y_val)\n",
    "\n",
    "                batch_val_size = y_val.size(0)\n",
    "                val_loss_total += val_loss.item() * batch_val_size\n",
    "                total_val_samples += batch_val_size\n",
    " \n",
    "                if task_type == \"classification\":\n",
    "                    if d_out == 1:\n",
    "\n",
    "                        val_preds = (val_logits > 0).long()\n",
    "                        val_targets = y_val.long()\n",
    "                    else:\n",
    "\n",
    "                        val_preds = torch.argmax(val_logits, dim=1)\n",
    "                        val_targets = y_val\n",
    "                    val_correct += (val_preds == val_targets).sum().item()\n",
    "\n",
    "        avg_val_loss = val_loss_total / total_val_samples\n",
    "        if task_type == \"classification\":\n",
    "            val_acc = val_correct / total_val_samples\n",
    "        else:\n",
    "            val_acc = None  \n",
    "        \n",
    "\n",
    "        current_val_score = val_acc if task_type == \"classification\" else -avg_val_loss\n",
    "\n",
    "        if best_val_score is None or (maximize_metric and current_val_score > best_val_score) or (not maximize_metric and current_val_score > best_val_score):\n",
    "            best_val_score = current_val_score\n",
    "            best_epoch = epoch\n",
    "            best_state = copy.deepcopy(model.state_dict())\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "\n",
    "        if task_type == \"classification\":\n",
    "            print(f\"Epoch {epoch:03d}: Train Loss = {avg_train_loss:.4f}, Train Acc = {train_acc:.4f}, \"\n",
    "                  f\"Val Loss = {avg_val_loss:.4f}, Val Acc = {val_acc:.4f}\")\n",
    "        else:\n",
    "            train_rmse = np.sqrt(avg_train_loss)\n",
    "            val_rmse = np.sqrt(avg_val_loss)\n",
    "            print(f\"Epoch {epoch:03d}: Train MSE = {avg_train_loss:.4f} (RMSE={train_rmse:.4f}), \"\n",
    "                  f\"Val MSE = {avg_val_loss:.4f} (RMSE={val_rmse:.4f})\")\n",
    "        \n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "    \n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "    results = {\"best_epoch\": best_epoch}\n",
    "    if task_type == \"classification\":\n",
    "        results[\"best_val_acc\"] = val_acc if best_val_score == val_acc else (best_val_score if maximize_metric else None)\n",
    "    else:\n",
    "        results[\"best_val_loss\"] = avg_val_loss if best_val_score == -avg_val_loss else (-best_val_score if not maximize_metric else None)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5372f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary classification\n",
      "(5625, 19) (5625,)\n",
      "(1407, 19) (1407,)\n",
      "Epoch 001: Train Loss = 0.5010, Train Acc = 0.7502, Val Loss = 0.4384, Val Acc = 0.7939\n",
      "Epoch 002: Train Loss = 0.4318, Train Acc = 0.7979, Val Loss = 0.4261, Val Acc = 0.7946\n",
      "Epoch 003: Train Loss = 0.4206, Train Acc = 0.8052, Val Loss = 0.4238, Val Acc = 0.7939\n",
      "Epoch 004: Train Loss = 0.4224, Train Acc = 0.7986, Val Loss = 0.4218, Val Acc = 0.8067\n",
      "Epoch 005: Train Loss = 0.4204, Train Acc = 0.7988, Val Loss = 0.4273, Val Acc = 0.7982\n",
      "Epoch 006: Train Loss = 0.4169, Train Acc = 0.8012, Val Loss = 0.4205, Val Acc = 0.8095\n",
      "Epoch 007: Train Loss = 0.4130, Train Acc = 0.8069, Val Loss = 0.4188, Val Acc = 0.8031\n",
      "Epoch 008: Train Loss = 0.4124, Train Acc = 0.8071, Val Loss = 0.4233, Val Acc = 0.7967\n",
      "Epoch 009: Train Loss = 0.4136, Train Acc = 0.8028, Val Loss = 0.4242, Val Acc = 0.8003\n",
      "Epoch 010: Train Loss = 0.4143, Train Acc = 0.8027, Val Loss = 0.4327, Val Acc = 0.7996\n",
      "Epoch 011: Train Loss = 0.4136, Train Acc = 0.8036, Val Loss = 0.4208, Val Acc = 0.7946\n",
      "Epoch 012: Train Loss = 0.4114, Train Acc = 0.8055, Val Loss = 0.4205, Val Acc = 0.7996\n",
      "Epoch 013: Train Loss = 0.4112, Train Acc = 0.8046, Val Loss = 0.4203, Val Acc = 0.8031\n",
      "Epoch 014: Train Loss = 0.4109, Train Acc = 0.8037, Val Loss = 0.4252, Val Acc = 0.7960\n",
      "Epoch 015: Train Loss = 0.4102, Train Acc = 0.8018, Val Loss = 0.4220, Val Acc = 0.7932\n",
      "Epoch 016: Train Loss = 0.4082, Train Acc = 0.8073, Val Loss = 0.4229, Val Acc = 0.8038\n",
      "Early stopping triggered.\n",
      "Churn Results: {'best_epoch': 6, 'best_val_acc': 0.8095238095238095}\n"
     ]
    }
   ],
   "source": [
    "# churn dataset\n",
    "data_loaders, n_cont, cat_cardinalities, d_out, task_type = prepare_data(\"churn\", batch_size=256)\n",
    "model = build_model(n_cont, cat_cardinalities, d_out)\n",
    "results = train_model(model, data_loaders[\"train\"], data_loaders[\"val\"], task_type, d_out, n_epochs=100, batch_size=256, patience=10, lr=1e-4)\n",
    "print(\"Churn Results:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4f6f968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary classification\n",
      "(30162, 15) (30162,)\n",
      "(15060, 15) (15060,)\n",
      "Epoch 001: Train Loss = 0.3496, Train Acc = 0.8333, Val Loss = 0.3197, Val Acc = 0.8474\n",
      "Epoch 002: Train Loss = 0.3180, Train Acc = 0.8525, Val Loss = 0.3152, Val Acc = 0.8490\n",
      "Epoch 003: Train Loss = 0.3122, Train Acc = 0.8558, Val Loss = 0.3117, Val Acc = 0.8553\n",
      "Epoch 004: Train Loss = 0.3111, Train Acc = 0.8546, Val Loss = 0.3113, Val Acc = 0.8553\n",
      "Epoch 005: Train Loss = 0.3085, Train Acc = 0.8553, Val Loss = 0.3103, Val Acc = 0.8542\n",
      "Epoch 006: Train Loss = 0.3076, Train Acc = 0.8555, Val Loss = 0.3105, Val Acc = 0.8552\n",
      "Epoch 007: Train Loss = 0.3053, Train Acc = 0.8596, Val Loss = 0.3285, Val Acc = 0.8548\n",
      "Epoch 008: Train Loss = 0.3047, Train Acc = 0.8586, Val Loss = 0.3098, Val Acc = 0.8535\n",
      "Epoch 009: Train Loss = 0.3025, Train Acc = 0.8589, Val Loss = 0.3143, Val Acc = 0.8550\n",
      "Epoch 010: Train Loss = 0.3012, Train Acc = 0.8606, Val Loss = 0.3129, Val Acc = 0.8535\n",
      "Epoch 011: Train Loss = 0.3039, Train Acc = 0.8571, Val Loss = 0.3131, Val Acc = 0.8533\n",
      "Epoch 012: Train Loss = 0.2998, Train Acc = 0.8606, Val Loss = 0.3103, Val Acc = 0.8530\n",
      "Epoch 013: Train Loss = 0.2979, Train Acc = 0.8611, Val Loss = 0.3173, Val Acc = 0.8482\n",
      "Early stopping triggered.\n",
      "adult Results: {'best_epoch': 3, 'best_val_acc': 0.8553120849933599}\n"
     ]
    }
   ],
   "source": [
    "# adult dataset\n",
    "data_loaders, n_cont, cat_cardinalities, d_out, task_type = prepare_data(\"adult\", batch_size=256)\n",
    "model = build_model(n_cont, cat_cardinalities, d_out)\n",
    "results = train_model(model, data_loaders[\"train\"], data_loaders[\"val\"], task_type, d_out, n_epochs=100, batch_size=256, patience=10, lr=3e-4)\n",
    "print(\"adult Results:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1dd1bf56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regression\n",
      "(16512, 8) (16512,)\n",
      "(4128, 8) (4128,)\n",
      "Epoch 001: Train MSE = 0.8081 (RMSE=0.8989), Val MSE = 0.4542 (RMSE=0.6739)\n",
      "Epoch 002: Train MSE = 0.3877 (RMSE=0.6226), Val MSE = 0.3440 (RMSE=0.5865)\n",
      "Epoch 003: Train MSE = 0.3489 (RMSE=0.5907), Val MSE = 0.3382 (RMSE=0.5815)\n",
      "Epoch 004: Train MSE = 0.3472 (RMSE=0.5893), Val MSE = 0.3228 (RMSE=0.5681)\n",
      "Epoch 005: Train MSE = 0.3206 (RMSE=0.5662), Val MSE = 0.3031 (RMSE=0.5505)\n",
      "Epoch 006: Train MSE = 0.3149 (RMSE=0.5612), Val MSE = 0.3015 (RMSE=0.5491)\n",
      "Epoch 007: Train MSE = 0.3031 (RMSE=0.5506), Val MSE = 0.3060 (RMSE=0.5532)\n",
      "Epoch 008: Train MSE = 0.2965 (RMSE=0.5445), Val MSE = 0.3153 (RMSE=0.5615)\n",
      "Epoch 009: Train MSE = 0.3047 (RMSE=0.5520), Val MSE = 0.2907 (RMSE=0.5392)\n",
      "Epoch 010: Train MSE = 0.2931 (RMSE=0.5414), Val MSE = 0.2905 (RMSE=0.5390)\n",
      "Epoch 011: Train MSE = 0.2822 (RMSE=0.5312), Val MSE = 0.2951 (RMSE=0.5433)\n",
      "Epoch 012: Train MSE = 0.2826 (RMSE=0.5316), Val MSE = 0.2915 (RMSE=0.5399)\n",
      "Epoch 013: Train MSE = 0.2831 (RMSE=0.5321), Val MSE = 0.3063 (RMSE=0.5535)\n",
      "Epoch 014: Train MSE = 0.2749 (RMSE=0.5243), Val MSE = 0.2960 (RMSE=0.5441)\n",
      "Epoch 015: Train MSE = 0.2765 (RMSE=0.5258), Val MSE = 0.2915 (RMSE=0.5399)\n",
      "Epoch 016: Train MSE = 0.2664 (RMSE=0.5161), Val MSE = 0.2890 (RMSE=0.5376)\n",
      "Epoch 017: Train MSE = 0.2669 (RMSE=0.5166), Val MSE = 0.2773 (RMSE=0.5266)\n",
      "Epoch 018: Train MSE = 0.2610 (RMSE=0.5109), Val MSE = 0.2927 (RMSE=0.5411)\n",
      "Epoch 019: Train MSE = 0.2567 (RMSE=0.5067), Val MSE = 0.2653 (RMSE=0.5150)\n",
      "Epoch 020: Train MSE = 0.2511 (RMSE=0.5011), Val MSE = 0.2736 (RMSE=0.5231)\n",
      "Epoch 021: Train MSE = 0.2600 (RMSE=0.5099), Val MSE = 0.2809 (RMSE=0.5300)\n",
      "Epoch 022: Train MSE = 0.2494 (RMSE=0.4994), Val MSE = 0.2716 (RMSE=0.5211)\n",
      "Epoch 023: Train MSE = 0.2460 (RMSE=0.4960), Val MSE = 0.2648 (RMSE=0.5146)\n",
      "Epoch 024: Train MSE = 0.2443 (RMSE=0.4942), Val MSE = 0.2595 (RMSE=0.5094)\n",
      "Epoch 025: Train MSE = 0.2431 (RMSE=0.4930), Val MSE = 0.2563 (RMSE=0.5062)\n",
      "Epoch 026: Train MSE = 0.2425 (RMSE=0.4925), Val MSE = 0.2561 (RMSE=0.5060)\n",
      "Epoch 027: Train MSE = 0.2368 (RMSE=0.4867), Val MSE = 0.2549 (RMSE=0.5048)\n",
      "Epoch 028: Train MSE = 0.2325 (RMSE=0.4822), Val MSE = 0.2568 (RMSE=0.5068)\n",
      "Epoch 029: Train MSE = 0.2379 (RMSE=0.4877), Val MSE = 0.2566 (RMSE=0.5065)\n",
      "Epoch 030: Train MSE = 0.2372 (RMSE=0.4870), Val MSE = 0.2658 (RMSE=0.5156)\n",
      "Epoch 031: Train MSE = 0.2347 (RMSE=0.4844), Val MSE = 0.2486 (RMSE=0.4986)\n",
      "Epoch 032: Train MSE = 0.2277 (RMSE=0.4772), Val MSE = 0.2568 (RMSE=0.5067)\n",
      "Epoch 033: Train MSE = 0.2301 (RMSE=0.4797), Val MSE = 0.2520 (RMSE=0.5020)\n",
      "Epoch 034: Train MSE = 0.2235 (RMSE=0.4728), Val MSE = 0.2610 (RMSE=0.5108)\n",
      "Epoch 035: Train MSE = 0.2266 (RMSE=0.4760), Val MSE = 0.2412 (RMSE=0.4912)\n",
      "Epoch 036: Train MSE = 0.2184 (RMSE=0.4673), Val MSE = 0.2442 (RMSE=0.4941)\n",
      "Epoch 037: Train MSE = 0.2230 (RMSE=0.4722), Val MSE = 0.2575 (RMSE=0.5075)\n",
      "Epoch 038: Train MSE = 0.2161 (RMSE=0.4649), Val MSE = 0.2439 (RMSE=0.4939)\n",
      "Epoch 039: Train MSE = 0.2163 (RMSE=0.4651), Val MSE = 0.2470 (RMSE=0.4970)\n",
      "Epoch 040: Train MSE = 0.2104 (RMSE=0.4587), Val MSE = 0.2473 (RMSE=0.4973)\n",
      "Epoch 041: Train MSE = 0.2158 (RMSE=0.4645), Val MSE = 0.2507 (RMSE=0.5007)\n",
      "Epoch 042: Train MSE = 0.2153 (RMSE=0.4640), Val MSE = 0.2490 (RMSE=0.4990)\n",
      "Epoch 043: Train MSE = 0.2078 (RMSE=0.4558), Val MSE = 0.2422 (RMSE=0.4921)\n",
      "Epoch 044: Train MSE = 0.2037 (RMSE=0.4514), Val MSE = 0.2606 (RMSE=0.5105)\n",
      "Epoch 045: Train MSE = 0.2065 (RMSE=0.4544), Val MSE = 0.2539 (RMSE=0.5039)\n",
      "Early stopping triggered.\n",
      "California Results: {'best_epoch': 35, 'best_val_loss': 0.2412431725813437}\n"
     ]
    }
   ],
   "source": [
    "# california dataset\n",
    "data_loaders, n_cont, cat_cardinalities, d_out, task_type = prepare_data(\"california\", batch_size=256)\n",
    "model = build_model(n_cont, cat_cardinalities, d_out)\n",
    "results = train_model(model, data_loaders[\"train\"], data_loaders[\"val\"], task_type, d_out, n_epochs=100, batch_size=256, patience=10, lr=3e-4)\n",
    "print(\"California Results:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3569c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary classification\n",
      "(8800000, 28) (8800000,)\n",
      "(2200000, 28) (2200000,)\n",
      "Epoch 001: Train Loss = 0.5091, Train Acc = 0.7430, Val Loss = 0.4903, Val Acc = 0.7570\n",
      "Epoch 002: Train Loss = 0.4881, Train Acc = 0.7576, Val Loss = 0.4774, Val Acc = 0.7648\n",
      "Epoch 003: Train Loss = 0.4801, Train Acc = 0.7631, Val Loss = 0.4729, Val Acc = 0.7681\n",
      "Epoch 004: Train Loss = 0.4752, Train Acc = 0.7663, Val Loss = 0.4680, Val Acc = 0.7711\n",
      "Epoch 005: Train Loss = 0.4715, Train Acc = 0.7687, Val Loss = 0.4658, Val Acc = 0.7725\n",
      "Epoch 006: Train Loss = 0.4681, Train Acc = 0.7711, Val Loss = 0.4619, Val Acc = 0.7755\n",
      "Epoch 007: Train Loss = 0.4655, Train Acc = 0.7727, Val Loss = 0.4613, Val Acc = 0.7758\n",
      "Epoch 008: Train Loss = 0.4634, Train Acc = 0.7739, Val Loss = 0.4586, Val Acc = 0.7777\n",
      "Epoch 009: Train Loss = 0.4618, Train Acc = 0.7750, Val Loss = 0.4587, Val Acc = 0.7779\n",
      "Epoch 010: Train Loss = 0.4603, Train Acc = 0.7760, Val Loss = 0.4558, Val Acc = 0.7792\n",
      "Epoch 011: Train Loss = 0.4591, Train Acc = 0.7768, Val Loss = 0.4547, Val Acc = 0.7799\n",
      "Epoch 012: Train Loss = 0.4580, Train Acc = 0.7774, Val Loss = 0.4534, Val Acc = 0.7807\n",
      "Epoch 013: Train Loss = 0.4571, Train Acc = 0.7782, Val Loss = 0.4536, Val Acc = 0.7808\n",
      "Epoch 014: Train Loss = 0.4563, Train Acc = 0.7786, Val Loss = 0.4546, Val Acc = 0.7808\n",
      "Epoch 015: Train Loss = 0.4553, Train Acc = 0.7792, Val Loss = 0.4520, Val Acc = 0.7815\n",
      "Epoch 016: Train Loss = 0.4546, Train Acc = 0.7796, Val Loss = 0.4522, Val Acc = 0.7816\n",
      "Epoch 017: Train Loss = 0.4539, Train Acc = 0.7802, Val Loss = 0.4513, Val Acc = 0.7822\n",
      "Epoch 018: Train Loss = 0.4531, Train Acc = 0.7805, Val Loss = 0.4510, Val Acc = 0.7827\n",
      "Epoch 019: Train Loss = 0.4525, Train Acc = 0.7810, Val Loss = 0.4508, Val Acc = 0.7826\n",
      "Epoch 020: Train Loss = 0.4520, Train Acc = 0.7812, Val Loss = 0.4494, Val Acc = 0.7837\n",
      "Epoch 021: Train Loss = 0.4515, Train Acc = 0.7816, Val Loss = 0.4495, Val Acc = 0.7831\n",
      "Epoch 022: Train Loss = 0.4510, Train Acc = 0.7819, Val Loss = 0.4489, Val Acc = 0.7837\n",
      "Epoch 023: Train Loss = 0.4504, Train Acc = 0.7824, Val Loss = 0.4495, Val Acc = 0.7832\n",
      "Epoch 024: Train Loss = 0.4500, Train Acc = 0.7826, Val Loss = 0.4482, Val Acc = 0.7842\n",
      "Epoch 025: Train Loss = 0.4495, Train Acc = 0.7830, Val Loss = 0.4487, Val Acc = 0.7842\n",
      "Epoch 026: Train Loss = 0.4490, Train Acc = 0.7831, Val Loss = 0.4497, Val Acc = 0.7837\n",
      "Epoch 027: Train Loss = 0.4486, Train Acc = 0.7834, Val Loss = 0.4492, Val Acc = 0.7842\n",
      "Epoch 028: Train Loss = 0.4483, Train Acc = 0.7836, Val Loss = 0.4485, Val Acc = 0.7846\n",
      "Epoch 029: Train Loss = 0.4479, Train Acc = 0.7838, Val Loss = 0.4478, Val Acc = 0.7848\n",
      "Epoch 030: Train Loss = 0.4475, Train Acc = 0.7840, Val Loss = 0.4485, Val Acc = 0.7844\n",
      "Epoch 031: Train Loss = 0.4472, Train Acc = 0.7843, Val Loss = 0.4483, Val Acc = 0.7845\n",
      "Epoch 032: Train Loss = 0.4469, Train Acc = 0.7845, Val Loss = 0.4460, Val Acc = 0.7853\n",
      "Epoch 033: Train Loss = 0.4465, Train Acc = 0.7848, Val Loss = 0.4465, Val Acc = 0.7856\n",
      "Epoch 034: Train Loss = 0.4461, Train Acc = 0.7850, Val Loss = 0.4472, Val Acc = 0.7853\n",
      "Epoch 035: Train Loss = 0.4458, Train Acc = 0.7852, Val Loss = 0.4473, Val Acc = 0.7852\n",
      "Epoch 036: Train Loss = 0.4455, Train Acc = 0.7855, Val Loss = 0.4466, Val Acc = 0.7852\n",
      "Epoch 037: Train Loss = 0.4452, Train Acc = 0.7855, Val Loss = 0.4470, Val Acc = 0.7858\n",
      "Epoch 038: Train Loss = 0.4450, Train Acc = 0.7858, Val Loss = 0.4465, Val Acc = 0.7855\n",
      "Epoch 039: Train Loss = 0.4447, Train Acc = 0.7859, Val Loss = 0.4481, Val Acc = 0.7846\n",
      "Epoch 040: Train Loss = 0.4444, Train Acc = 0.7860, Val Loss = 0.4452, Val Acc = 0.7861\n",
      "Epoch 041: Train Loss = 0.4441, Train Acc = 0.7863, Val Loss = 0.4468, Val Acc = 0.7851\n",
      "Epoch 042: Train Loss = 0.4438, Train Acc = 0.7864, Val Loss = 0.4469, Val Acc = 0.7856\n",
      "Epoch 043: Train Loss = 0.4436, Train Acc = 0.7867, Val Loss = 0.4486, Val Acc = 0.7847\n",
      "Epoch 044: Train Loss = 0.4434, Train Acc = 0.7867, Val Loss = 0.4469, Val Acc = 0.7851\n",
      "Epoch 045: Train Loss = 0.4431, Train Acc = 0.7869, Val Loss = 0.4464, Val Acc = 0.7864\n",
      "Epoch 046: Train Loss = 0.4429, Train Acc = 0.7869, Val Loss = 0.4453, Val Acc = 0.7862\n",
      "Epoch 047: Train Loss = 0.4427, Train Acc = 0.7872, Val Loss = 0.4478, Val Acc = 0.7852\n",
      "Epoch 048: Train Loss = 0.4425, Train Acc = 0.7873, Val Loss = 0.4454, Val Acc = 0.7861\n",
      "Epoch 049: Train Loss = 0.4422, Train Acc = 0.7874, Val Loss = 0.4458, Val Acc = 0.7859\n",
      "Epoch 050: Train Loss = 0.4420, Train Acc = 0.7876, Val Loss = 0.4456, Val Acc = 0.7865\n",
      "Epoch 051: Train Loss = 0.4418, Train Acc = 0.7875, Val Loss = 0.4464, Val Acc = 0.7861\n",
      "Epoch 052: Train Loss = 0.4416, Train Acc = 0.7879, Val Loss = 0.4467, Val Acc = 0.7861\n",
      "Epoch 053: Train Loss = 0.4414, Train Acc = 0.7878, Val Loss = 0.4469, Val Acc = 0.7861\n",
      "Epoch 054: Train Loss = 0.4411, Train Acc = 0.7881, Val Loss = 0.4463, Val Acc = 0.7859\n",
      "Epoch 055: Train Loss = 0.4409, Train Acc = 0.7882, Val Loss = 0.4458, Val Acc = 0.7864\n",
      "Epoch 056: Train Loss = 0.4408, Train Acc = 0.7883, Val Loss = 0.4459, Val Acc = 0.7865\n",
      "Epoch 057: Train Loss = 0.4405, Train Acc = 0.7885, Val Loss = 0.4447, Val Acc = 0.7869\n",
      "Epoch 058: Train Loss = 0.4404, Train Acc = 0.7885, Val Loss = 0.4453, Val Acc = 0.7865\n",
      "Epoch 059: Train Loss = 0.4402, Train Acc = 0.7886, Val Loss = 0.4449, Val Acc = 0.7867\n",
      "Epoch 060: Train Loss = 0.4400, Train Acc = 0.7887, Val Loss = 0.4470, Val Acc = 0.7861\n",
      "Epoch 061: Train Loss = 0.4399, Train Acc = 0.7889, Val Loss = 0.4467, Val Acc = 0.7863\n",
      "Epoch 062: Train Loss = 0.4396, Train Acc = 0.7891, Val Loss = 0.4470, Val Acc = 0.7858\n",
      "Epoch 063: Train Loss = 0.4394, Train Acc = 0.7891, Val Loss = 0.4454, Val Acc = 0.7863\n",
      "Epoch 064: Train Loss = 0.4392, Train Acc = 0.7893, Val Loss = 0.4464, Val Acc = 0.7858\n",
      "Epoch 065: Train Loss = 0.4392, Train Acc = 0.7893, Val Loss = 0.4455, Val Acc = 0.7868\n",
      "Epoch 066: Train Loss = 0.4389, Train Acc = 0.7894, Val Loss = 0.4456, Val Acc = 0.7864\n",
      "Epoch 067: Train Loss = 0.4387, Train Acc = 0.7896, Val Loss = 0.4468, Val Acc = 0.7862\n",
      "Early stopping triggered.\n",
      "Higgs Results: {'best_epoch': 57, 'best_val_acc': 0.7868504545454545}\n"
     ]
    }
   ],
   "source": [
    "# higgs dataset\n",
    "data_loaders, n_cont, cat_cardinalities, d_out, task_type = prepare_data(\"higgs\", batch_size=256)\n",
    "model = build_model(n_cont, cat_cardinalities, d_out)\n",
    "results = train_model(model, data_loaders[\"train\"], data_loaders[\"val\"], task_type, d_out, n_epochs=100, batch_size=256, patience=10, lr=3e-4)\n",
    "print(\"Higgs Results:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc99f034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary classification\n",
      "(227845, 30) (227845,)\n",
      "(56962, 30) (56962,)\n",
      "Epoch 001: Train Loss = 0.0066, Train Acc = 0.9992, Val Loss = 0.0030, Val Acc = 0.9995\n",
      "Epoch 002: Train Loss = 0.0035, Train Acc = 0.9994, Val Loss = 0.0031, Val Acc = 0.9994\n",
      "Epoch 003: Train Loss = 0.0034, Train Acc = 0.9993, Val Loss = 0.0030, Val Acc = 0.9994\n",
      "Epoch 004: Train Loss = 0.0033, Train Acc = 0.9994, Val Loss = 0.0043, Val Acc = 0.9990\n",
      "Epoch 005: Train Loss = 0.0032, Train Acc = 0.9994, Val Loss = 0.0026, Val Acc = 0.9995\n",
      "Epoch 006: Train Loss = 0.0031, Train Acc = 0.9993, Val Loss = 0.0030, Val Acc = 0.9992\n",
      "Epoch 007: Train Loss = 0.0031, Train Acc = 0.9994, Val Loss = 0.0028, Val Acc = 0.9994\n",
      "Epoch 008: Train Loss = 0.0031, Train Acc = 0.9994, Val Loss = 0.0025, Val Acc = 0.9995\n",
      "Epoch 009: Train Loss = 0.0030, Train Acc = 0.9994, Val Loss = 0.0026, Val Acc = 0.9995\n",
      "Epoch 010: Train Loss = 0.0029, Train Acc = 0.9994, Val Loss = 0.0024, Val Acc = 0.9995\n",
      "Epoch 011: Train Loss = 0.0030, Train Acc = 0.9994, Val Loss = 0.0024, Val Acc = 0.9995\n",
      "Epoch 012: Train Loss = 0.0029, Train Acc = 0.9994, Val Loss = 0.0024, Val Acc = 0.9995\n",
      "Epoch 013: Train Loss = 0.0029, Train Acc = 0.9994, Val Loss = 0.0024, Val Acc = 0.9995\n",
      "Epoch 014: Train Loss = 0.0029, Train Acc = 0.9994, Val Loss = 0.0024, Val Acc = 0.9995\n",
      "Epoch 015: Train Loss = 0.0029, Train Acc = 0.9994, Val Loss = 0.0024, Val Acc = 0.9995\n",
      "Epoch 016: Train Loss = 0.0029, Train Acc = 0.9994, Val Loss = 0.0025, Val Acc = 0.9995\n",
      "Epoch 017: Train Loss = 0.0029, Train Acc = 0.9994, Val Loss = 0.0024, Val Acc = 0.9994\n",
      "Epoch 018: Train Loss = 0.0029, Train Acc = 0.9994, Val Loss = 0.0024, Val Acc = 0.9995\n",
      "Epoch 019: Train Loss = 0.0029, Train Acc = 0.9994, Val Loss = 0.0022, Val Acc = 0.9995\n",
      "Epoch 020: Train Loss = 0.0028, Train Acc = 0.9994, Val Loss = 0.0024, Val Acc = 0.9995\n",
      "Epoch 021: Train Loss = 0.0028, Train Acc = 0.9994, Val Loss = 0.0027, Val Acc = 0.9994\n",
      "Early stopping triggered.\n",
      "Credit Card Results: {'best_epoch': 11, 'best_val_acc': 0.9995259997893332}\n"
     ]
    }
   ],
   "source": [
    "# creditcard dataset\n",
    "data_loaders, n_cont, cat_cardinalities, d_out, task_type = prepare_data(\"creditcard\", batch_size=256)\n",
    "model = build_model(n_cont, cat_cardinalities, d_out)\n",
    "results = train_model(model, data_loaders[\"train\"], data_loaders[\"val\"], task_type, d_out, n_epochs=100, batch_size=256, patience=10, lr=3e-4)\n",
    "print(\"Credit Card Results:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92f83392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi-class classification\n",
      "(25010, 10) (25010,)\n",
      "(1000000, 10) (1000000,)\n",
      "Epoch 001: Train Loss = 1.0224, Train Acc = 0.4844, Val Loss = 0.9874, Val Acc = 0.5012\n",
      "Epoch 002: Train Loss = 0.9891, Train Acc = 0.4974, Val Loss = 0.9864, Val Acc = 0.4886\n",
      "Epoch 003: Train Loss = 0.9866, Train Acc = 0.4980, Val Loss = 0.9847, Val Acc = 0.4970\n",
      "Epoch 004: Train Loss = 0.9865, Train Acc = 0.4922, Val Loss = 0.9833, Val Acc = 0.5012\n",
      "Epoch 005: Train Loss = 0.9800, Train Acc = 0.5020, Val Loss = 0.9673, Val Acc = 0.5268\n",
      "Epoch 006: Train Loss = 0.9391, Train Acc = 0.5569, Val Loss = 0.8887, Val Acc = 0.5923\n",
      "Epoch 007: Train Loss = 0.8736, Train Acc = 0.6044, Val Loss = 0.8074, Val Acc = 0.6492\n",
      "Epoch 008: Train Loss = 0.7811, Train Acc = 0.6592, Val Loss = 0.7066, Val Acc = 0.6964\n",
      "Epoch 009: Train Loss = 0.6794, Train Acc = 0.7137, Val Loss = 0.5553, Val Acc = 0.7731\n",
      "Epoch 010: Train Loss = 0.5499, Train Acc = 0.7757, Val Loss = 0.4349, Val Acc = 0.8253\n",
      "Epoch 011: Train Loss = 0.4142, Train Acc = 0.8373, Val Loss = 0.2649, Val Acc = 0.9034\n",
      "Epoch 012: Train Loss = 0.2512, Train Acc = 0.9088, Val Loss = 0.0978, Val Acc = 0.9672\n",
      "Epoch 013: Train Loss = 0.1416, Train Acc = 0.9519, Val Loss = 0.0733, Val Acc = 0.9755\n",
      "Epoch 014: Train Loss = 0.1035, Train Acc = 0.9662, Val Loss = 0.0623, Val Acc = 0.9798\n",
      "Epoch 015: Train Loss = 0.0887, Train Acc = 0.9714, Val Loss = 0.0529, Val Acc = 0.9841\n",
      "Epoch 016: Train Loss = 0.0817, Train Acc = 0.9740, Val Loss = 0.0546, Val Acc = 0.9830\n",
      "Epoch 017: Train Loss = 0.0689, Train Acc = 0.9790, Val Loss = 0.0449, Val Acc = 0.9862\n",
      "Epoch 018: Train Loss = 0.0618, Train Acc = 0.9815, Val Loss = 0.0419, Val Acc = 0.9884\n",
      "Epoch 019: Train Loss = 0.0582, Train Acc = 0.9828, Val Loss = 0.0373, Val Acc = 0.9895\n",
      "Epoch 020: Train Loss = 0.0485, Train Acc = 0.9860, Val Loss = 0.0316, Val Acc = 0.9919\n",
      "Epoch 021: Train Loss = 0.0530, Train Acc = 0.9842, Val Loss = 0.0332, Val Acc = 0.9911\n",
      "Epoch 022: Train Loss = 0.0484, Train Acc = 0.9863, Val Loss = 0.0291, Val Acc = 0.9922\n",
      "Epoch 023: Train Loss = 0.0413, Train Acc = 0.9883, Val Loss = 0.0285, Val Acc = 0.9927\n",
      "Epoch 024: Train Loss = 0.0447, Train Acc = 0.9872, Val Loss = 0.0335, Val Acc = 0.9913\n",
      "Epoch 025: Train Loss = 0.0382, Train Acc = 0.9896, Val Loss = 0.0267, Val Acc = 0.9931\n",
      "Epoch 026: Train Loss = 0.0344, Train Acc = 0.9904, Val Loss = 0.0261, Val Acc = 0.9933\n",
      "Epoch 027: Train Loss = 0.0332, Train Acc = 0.9911, Val Loss = 0.0311, Val Acc = 0.9919\n",
      "Epoch 028: Train Loss = 0.0376, Train Acc = 0.9901, Val Loss = 0.0280, Val Acc = 0.9930\n",
      "Epoch 029: Train Loss = 0.0371, Train Acc = 0.9898, Val Loss = 0.0264, Val Acc = 0.9933\n",
      "Epoch 030: Train Loss = 0.0329, Train Acc = 0.9915, Val Loss = 0.0276, Val Acc = 0.9929\n",
      "Epoch 031: Train Loss = 0.0296, Train Acc = 0.9921, Val Loss = 0.0206, Val Acc = 0.9955\n",
      "Epoch 032: Train Loss = 0.0290, Train Acc = 0.9922, Val Loss = 0.0298, Val Acc = 0.9921\n",
      "Epoch 033: Train Loss = 0.0315, Train Acc = 0.9921, Val Loss = 0.0230, Val Acc = 0.9946\n",
      "Epoch 034: Train Loss = 0.0285, Train Acc = 0.9926, Val Loss = 0.0245, Val Acc = 0.9943\n",
      "Epoch 035: Train Loss = 0.0310, Train Acc = 0.9921, Val Loss = 0.0251, Val Acc = 0.9944\n",
      "Epoch 036: Train Loss = 0.0341, Train Acc = 0.9910, Val Loss = 0.0223, Val Acc = 0.9947\n",
      "Epoch 037: Train Loss = 0.0272, Train Acc = 0.9929, Val Loss = 0.0250, Val Acc = 0.9942\n",
      "Epoch 038: Train Loss = 0.0320, Train Acc = 0.9920, Val Loss = 0.0236, Val Acc = 0.9947\n",
      "Epoch 039: Train Loss = 0.0229, Train Acc = 0.9950, Val Loss = 0.0237, Val Acc = 0.9944\n",
      "Epoch 040: Train Loss = 0.0256, Train Acc = 0.9941, Val Loss = 0.0331, Val Acc = 0.9917\n",
      "Epoch 041: Train Loss = 0.0280, Train Acc = 0.9923, Val Loss = 0.0243, Val Acc = 0.9946\n",
      "Early stopping triggered.\n",
      "Poker Results: {'best_epoch': 31, 'best_val_acc': 0.995484}\n"
     ]
    }
   ],
   "source": [
    "# poker dataset\n",
    "data_loaders, n_cont, cat_cardinalities, d_out, task_type = prepare_data(\"poker\", batch_size=256)\n",
    "model = build_model(n_cont, cat_cardinalities, d_out)\n",
    "results = train_model(model, data_loaders[\"train\"], data_loaders[\"val\"], task_type, d_out, n_epochs=100, batch_size=256, patience=10, lr=3e-4)\n",
    "print(\"Poker Results:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5cdaeea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi-class classification\n",
      "(2558, 11) (2558,)\n",
      "(640, 11) (640,)\n",
      "Epoch 001: Train MSE = 8.3010 (RMSE=2.8811), Val MSE = 2.6171 (RMSE=1.6177)\n",
      "Epoch 002: Train MSE = 2.2249 (RMSE=1.4916), Val MSE = 1.6618 (RMSE=1.2891)\n",
      "Epoch 003: Train MSE = 1.5123 (RMSE=1.2298), Val MSE = 1.2104 (RMSE=1.1002)\n",
      "Epoch 004: Train MSE = 1.1265 (RMSE=1.0614), Val MSE = 0.9403 (RMSE=0.9697)\n",
      "Epoch 005: Train MSE = 0.8996 (RMSE=0.9485), Val MSE = 0.7833 (RMSE=0.8850)\n",
      "Epoch 006: Train MSE = 0.7654 (RMSE=0.8749), Val MSE = 0.7030 (RMSE=0.8385)\n",
      "Epoch 007: Train MSE = 0.6983 (RMSE=0.8356), Val MSE = 0.6659 (RMSE=0.8160)\n",
      "Epoch 008: Train MSE = 0.6680 (RMSE=0.8173), Val MSE = 0.6520 (RMSE=0.8074)\n",
      "Epoch 009: Train MSE = 0.6549 (RMSE=0.8092), Val MSE = 0.6481 (RMSE=0.8050)\n",
      "Epoch 010: Train MSE = 0.6505 (RMSE=0.8065), Val MSE = 0.6469 (RMSE=0.8043)\n",
      "Epoch 011: Train MSE = 0.6481 (RMSE=0.8050), Val MSE = 0.6451 (RMSE=0.8032)\n",
      "Epoch 012: Train MSE = 0.6460 (RMSE=0.8037), Val MSE = 0.6417 (RMSE=0.8011)\n",
      "Epoch 013: Train MSE = 0.6426 (RMSE=0.8016), Val MSE = 0.6368 (RMSE=0.7980)\n",
      "Epoch 014: Train MSE = 0.6375 (RMSE=0.7985), Val MSE = 0.6293 (RMSE=0.7933)\n",
      "Epoch 015: Train MSE = 0.6300 (RMSE=0.7937), Val MSE = 0.6182 (RMSE=0.7862)\n",
      "Epoch 016: Train MSE = 0.6140 (RMSE=0.7836), Val MSE = 0.5917 (RMSE=0.7692)\n",
      "Epoch 017: Train MSE = 0.5838 (RMSE=0.7641), Val MSE = 0.5456 (RMSE=0.7386)\n",
      "Epoch 018: Train MSE = 0.5466 (RMSE=0.7393), Val MSE = 0.5075 (RMSE=0.7124)\n",
      "Epoch 019: Train MSE = 0.5168 (RMSE=0.7189), Val MSE = 0.4784 (RMSE=0.6917)\n",
      "Epoch 020: Train MSE = 0.4941 (RMSE=0.7029), Val MSE = 0.4646 (RMSE=0.6816)\n",
      "Epoch 021: Train MSE = 0.4732 (RMSE=0.6879), Val MSE = 0.4473 (RMSE=0.6688)\n",
      "Epoch 022: Train MSE = 0.4651 (RMSE=0.6820), Val MSE = 0.4265 (RMSE=0.6531)\n",
      "Epoch 023: Train MSE = 0.4531 (RMSE=0.6731), Val MSE = 0.4254 (RMSE=0.6523)\n",
      "Epoch 024: Train MSE = 0.4441 (RMSE=0.6664), Val MSE = 0.4190 (RMSE=0.6473)\n",
      "Epoch 025: Train MSE = 0.4322 (RMSE=0.6574), Val MSE = 0.4014 (RMSE=0.6335)\n",
      "Epoch 026: Train MSE = 0.4300 (RMSE=0.6557), Val MSE = 0.3967 (RMSE=0.6298)\n",
      "Epoch 027: Train MSE = 0.4183 (RMSE=0.6468), Val MSE = 0.3916 (RMSE=0.6258)\n",
      "Epoch 028: Train MSE = 0.4143 (RMSE=0.6437), Val MSE = 0.3963 (RMSE=0.6296)\n",
      "Epoch 029: Train MSE = 0.4121 (RMSE=0.6420), Val MSE = 0.3830 (RMSE=0.6188)\n",
      "Epoch 030: Train MSE = 0.4034 (RMSE=0.6352), Val MSE = 0.3798 (RMSE=0.6163)\n",
      "Epoch 031: Train MSE = 0.3969 (RMSE=0.6300), Val MSE = 0.3742 (RMSE=0.6118)\n",
      "Epoch 032: Train MSE = 0.3936 (RMSE=0.6274), Val MSE = 0.3721 (RMSE=0.6100)\n",
      "Epoch 033: Train MSE = 0.3958 (RMSE=0.6291), Val MSE = 0.3696 (RMSE=0.6079)\n",
      "Epoch 034: Train MSE = 0.3932 (RMSE=0.6271), Val MSE = 0.3682 (RMSE=0.6068)\n",
      "Epoch 035: Train MSE = 0.3917 (RMSE=0.6258), Val MSE = 0.3652 (RMSE=0.6043)\n",
      "Epoch 036: Train MSE = 0.3864 (RMSE=0.6216), Val MSE = 0.3652 (RMSE=0.6043)\n",
      "Epoch 037: Train MSE = 0.3857 (RMSE=0.6210), Val MSE = 0.3627 (RMSE=0.6023)\n",
      "Epoch 038: Train MSE = 0.3882 (RMSE=0.6231), Val MSE = 0.3601 (RMSE=0.6000)\n",
      "Epoch 039: Train MSE = 0.3783 (RMSE=0.6150), Val MSE = 0.3602 (RMSE=0.6002)\n",
      "Epoch 040: Train MSE = 0.3832 (RMSE=0.6190), Val MSE = 0.3588 (RMSE=0.5990)\n",
      "Epoch 041: Train MSE = 0.3784 (RMSE=0.6151), Val MSE = 0.3595 (RMSE=0.5996)\n",
      "Epoch 042: Train MSE = 0.3770 (RMSE=0.6140), Val MSE = 0.3613 (RMSE=0.6011)\n",
      "Epoch 043: Train MSE = 0.3760 (RMSE=0.6132), Val MSE = 0.3568 (RMSE=0.5973)\n",
      "Epoch 044: Train MSE = 0.3742 (RMSE=0.6117), Val MSE = 0.3564 (RMSE=0.5970)\n",
      "Epoch 045: Train MSE = 0.3726 (RMSE=0.6104), Val MSE = 0.3583 (RMSE=0.5986)\n",
      "Epoch 046: Train MSE = 0.3659 (RMSE=0.6049), Val MSE = 0.3535 (RMSE=0.5945)\n",
      "Epoch 047: Train MSE = 0.3666 (RMSE=0.6055), Val MSE = 0.3511 (RMSE=0.5926)\n",
      "Epoch 048: Train MSE = 0.3666 (RMSE=0.6055), Val MSE = 0.3521 (RMSE=0.5934)\n",
      "Epoch 049: Train MSE = 0.3662 (RMSE=0.6052), Val MSE = 0.3605 (RMSE=0.6004)\n",
      "Epoch 050: Train MSE = 0.3708 (RMSE=0.6090), Val MSE = 0.3865 (RMSE=0.6217)\n",
      "Epoch 051: Train MSE = 0.3798 (RMSE=0.6163), Val MSE = 0.3675 (RMSE=0.6062)\n",
      "Epoch 052: Train MSE = 0.3727 (RMSE=0.6105), Val MSE = 0.3498 (RMSE=0.5914)\n",
      "Epoch 053: Train MSE = 0.3694 (RMSE=0.6077), Val MSE = 0.3558 (RMSE=0.5965)\n",
      "Epoch 054: Train MSE = 0.3600 (RMSE=0.6000), Val MSE = 0.3466 (RMSE=0.5887)\n",
      "Epoch 055: Train MSE = 0.3517 (RMSE=0.5931), Val MSE = 0.3516 (RMSE=0.5929)\n",
      "Epoch 056: Train MSE = 0.3539 (RMSE=0.5949), Val MSE = 0.3506 (RMSE=0.5921)\n",
      "Epoch 057: Train MSE = 0.3494 (RMSE=0.5911), Val MSE = 0.3407 (RMSE=0.5837)\n",
      "Epoch 058: Train MSE = 0.3432 (RMSE=0.5858), Val MSE = 0.3459 (RMSE=0.5882)\n",
      "Epoch 059: Train MSE = 0.3425 (RMSE=0.5853), Val MSE = 0.3418 (RMSE=0.5846)\n",
      "Epoch 060: Train MSE = 0.3427 (RMSE=0.5854), Val MSE = 0.3385 (RMSE=0.5818)\n",
      "Epoch 061: Train MSE = 0.3398 (RMSE=0.5829), Val MSE = 0.3352 (RMSE=0.5789)\n",
      "Epoch 062: Train MSE = 0.3351 (RMSE=0.5789), Val MSE = 0.3334 (RMSE=0.5774)\n",
      "Epoch 063: Train MSE = 0.3353 (RMSE=0.5790), Val MSE = 0.3324 (RMSE=0.5766)\n",
      "Epoch 064: Train MSE = 0.3344 (RMSE=0.5782), Val MSE = 0.3347 (RMSE=0.5785)\n",
      "Epoch 065: Train MSE = 0.3218 (RMSE=0.5673), Val MSE = 0.3281 (RMSE=0.5728)\n",
      "Epoch 066: Train MSE = 0.3228 (RMSE=0.5681), Val MSE = 0.3304 (RMSE=0.5748)\n",
      "Epoch 067: Train MSE = 0.3233 (RMSE=0.5686), Val MSE = 0.3273 (RMSE=0.5721)\n",
      "Epoch 068: Train MSE = 0.3192 (RMSE=0.5650), Val MSE = 0.3220 (RMSE=0.5675)\n",
      "Epoch 069: Train MSE = 0.3111 (RMSE=0.5578), Val MSE = 0.3250 (RMSE=0.5701)\n",
      "Epoch 070: Train MSE = 0.3080 (RMSE=0.5550), Val MSE = 0.3221 (RMSE=0.5676)\n",
      "Epoch 071: Train MSE = 0.3072 (RMSE=0.5542), Val MSE = 0.3199 (RMSE=0.5656)\n",
      "Epoch 072: Train MSE = 0.3010 (RMSE=0.5487), Val MSE = 0.3111 (RMSE=0.5578)\n",
      "Epoch 073: Train MSE = 0.2897 (RMSE=0.5383), Val MSE = 0.3114 (RMSE=0.5581)\n",
      "Epoch 074: Train MSE = 0.2864 (RMSE=0.5351), Val MSE = 0.3050 (RMSE=0.5523)\n",
      "Epoch 075: Train MSE = 0.2983 (RMSE=0.5461), Val MSE = 0.3111 (RMSE=0.5578)\n",
      "Epoch 076: Train MSE = 0.3031 (RMSE=0.5505), Val MSE = 0.2978 (RMSE=0.5457)\n",
      "Epoch 077: Train MSE = 0.2911 (RMSE=0.5396), Val MSE = 0.2996 (RMSE=0.5474)\n",
      "Epoch 078: Train MSE = 0.2743 (RMSE=0.5237), Val MSE = 0.2872 (RMSE=0.5359)\n",
      "Epoch 079: Train MSE = 0.2723 (RMSE=0.5218), Val MSE = 0.2893 (RMSE=0.5379)\n",
      "Epoch 080: Train MSE = 0.2690 (RMSE=0.5186), Val MSE = 0.2997 (RMSE=0.5474)\n",
      "Epoch 081: Train MSE = 0.2682 (RMSE=0.5179), Val MSE = 0.2916 (RMSE=0.5400)\n",
      "Epoch 082: Train MSE = 0.2677 (RMSE=0.5174), Val MSE = 0.2766 (RMSE=0.5259)\n",
      "Epoch 083: Train MSE = 0.2607 (RMSE=0.5105), Val MSE = 0.2795 (RMSE=0.5287)\n",
      "Epoch 084: Train MSE = 0.2514 (RMSE=0.5014), Val MSE = 0.2923 (RMSE=0.5406)\n",
      "Epoch 085: Train MSE = 0.2533 (RMSE=0.5032), Val MSE = 0.2685 (RMSE=0.5182)\n",
      "Epoch 086: Train MSE = 0.2478 (RMSE=0.4978), Val MSE = 0.2672 (RMSE=0.5169)\n",
      "Epoch 087: Train MSE = 0.2392 (RMSE=0.4891), Val MSE = 0.2558 (RMSE=0.5058)\n",
      "Epoch 088: Train MSE = 0.2344 (RMSE=0.4841), Val MSE = 0.2756 (RMSE=0.5249)\n",
      "Epoch 089: Train MSE = 0.2357 (RMSE=0.4854), Val MSE = 0.2545 (RMSE=0.5045)\n",
      "Epoch 090: Train MSE = 0.2328 (RMSE=0.4825), Val MSE = 0.2665 (RMSE=0.5163)\n",
      "Epoch 091: Train MSE = 0.2256 (RMSE=0.4749), Val MSE = 0.2553 (RMSE=0.5053)\n",
      "Epoch 092: Train MSE = 0.2236 (RMSE=0.4729), Val MSE = 0.2406 (RMSE=0.4905)\n",
      "Epoch 093: Train MSE = 0.2125 (RMSE=0.4610), Val MSE = 0.2770 (RMSE=0.5263)\n",
      "Epoch 094: Train MSE = 0.2136 (RMSE=0.4621), Val MSE = 0.2362 (RMSE=0.4860)\n",
      "Epoch 095: Train MSE = 0.2096 (RMSE=0.4579), Val MSE = 0.2356 (RMSE=0.4854)\n",
      "Epoch 096: Train MSE = 0.1978 (RMSE=0.4448), Val MSE = 0.2534 (RMSE=0.5034)\n",
      "Epoch 097: Train MSE = 0.1965 (RMSE=0.4432), Val MSE = 0.2205 (RMSE=0.4696)\n",
      "Epoch 098: Train MSE = 0.1921 (RMSE=0.4383), Val MSE = 0.2272 (RMSE=0.4767)\n",
      "Epoch 099: Train MSE = 0.1823 (RMSE=0.4270), Val MSE = 0.2174 (RMSE=0.4663)\n",
      "Epoch 100: Train MSE = 0.1775 (RMSE=0.4213), Val MSE = 0.2197 (RMSE=0.4688)\n",
      "Epoch 101: Train MSE = 0.1821 (RMSE=0.4268), Val MSE = 0.2074 (RMSE=0.4554)\n",
      "Epoch 102: Train MSE = 0.1697 (RMSE=0.4119), Val MSE = 0.2010 (RMSE=0.4484)\n",
      "Epoch 103: Train MSE = 0.1769 (RMSE=0.4206), Val MSE = 0.2292 (RMSE=0.4787)\n",
      "Epoch 104: Train MSE = 0.1665 (RMSE=0.4080), Val MSE = 0.1970 (RMSE=0.4439)\n",
      "Epoch 105: Train MSE = 0.1633 (RMSE=0.4041), Val MSE = 0.2012 (RMSE=0.4485)\n",
      "Epoch 106: Train MSE = 0.1560 (RMSE=0.3950), Val MSE = 0.1862 (RMSE=0.4315)\n",
      "Epoch 107: Train MSE = 0.1577 (RMSE=0.3972), Val MSE = 0.1823 (RMSE=0.4270)\n",
      "Epoch 108: Train MSE = 0.1518 (RMSE=0.3896), Val MSE = 0.1693 (RMSE=0.4115)\n",
      "Epoch 109: Train MSE = 0.1460 (RMSE=0.3820), Val MSE = 0.1936 (RMSE=0.4400)\n",
      "Epoch 110: Train MSE = 0.1486 (RMSE=0.3855), Val MSE = 0.1719 (RMSE=0.4146)\n",
      "Epoch 111: Train MSE = 0.1391 (RMSE=0.3730), Val MSE = 0.1660 (RMSE=0.4075)\n",
      "Epoch 112: Train MSE = 0.1364 (RMSE=0.3693), Val MSE = 0.1652 (RMSE=0.4065)\n",
      "Epoch 113: Train MSE = 0.1342 (RMSE=0.3664), Val MSE = 0.1788 (RMSE=0.4228)\n",
      "Epoch 114: Train MSE = 0.1242 (RMSE=0.3525), Val MSE = 0.1541 (RMSE=0.3926)\n",
      "Epoch 115: Train MSE = 0.1258 (RMSE=0.3547), Val MSE = 0.1677 (RMSE=0.4095)\n",
      "Epoch 116: Train MSE = 0.1232 (RMSE=0.3511), Val MSE = 0.1459 (RMSE=0.3820)\n",
      "Epoch 117: Train MSE = 0.1225 (RMSE=0.3500), Val MSE = 0.1460 (RMSE=0.3821)\n",
      "Epoch 118: Train MSE = 0.1179 (RMSE=0.3433), Val MSE = 0.1324 (RMSE=0.3639)\n",
      "Epoch 119: Train MSE = 0.1156 (RMSE=0.3400), Val MSE = 0.1477 (RMSE=0.3843)\n",
      "Epoch 120: Train MSE = 0.1120 (RMSE=0.3347), Val MSE = 0.1383 (RMSE=0.3719)\n",
      "Epoch 121: Train MSE = 0.1115 (RMSE=0.3339), Val MSE = 0.1349 (RMSE=0.3672)\n",
      "Epoch 122: Train MSE = 0.1076 (RMSE=0.3280), Val MSE = 0.1384 (RMSE=0.3720)\n",
      "Epoch 123: Train MSE = 0.1054 (RMSE=0.3246), Val MSE = 0.1358 (RMSE=0.3685)\n",
      "Epoch 124: Train MSE = 0.1009 (RMSE=0.3177), Val MSE = 0.1223 (RMSE=0.3497)\n",
      "Epoch 125: Train MSE = 0.0946 (RMSE=0.3076), Val MSE = 0.1194 (RMSE=0.3456)\n",
      "Epoch 126: Train MSE = 0.0964 (RMSE=0.3104), Val MSE = 0.1216 (RMSE=0.3487)\n",
      "Epoch 127: Train MSE = 0.0933 (RMSE=0.3054), Val MSE = 0.1312 (RMSE=0.3622)\n",
      "Epoch 128: Train MSE = 0.0960 (RMSE=0.3099), Val MSE = 0.1209 (RMSE=0.3477)\n",
      "Epoch 129: Train MSE = 0.0953 (RMSE=0.3088), Val MSE = 0.1409 (RMSE=0.3754)\n",
      "Epoch 130: Train MSE = 0.1012 (RMSE=0.3182), Val MSE = 0.1017 (RMSE=0.3190)\n",
      "Epoch 131: Train MSE = 0.0923 (RMSE=0.3038), Val MSE = 0.1270 (RMSE=0.3564)\n",
      "Epoch 132: Train MSE = 0.0856 (RMSE=0.2925), Val MSE = 0.1091 (RMSE=0.3303)\n",
      "Epoch 133: Train MSE = 0.0805 (RMSE=0.2837), Val MSE = 0.1017 (RMSE=0.3188)\n",
      "Epoch 134: Train MSE = 0.0793 (RMSE=0.2815), Val MSE = 0.1091 (RMSE=0.3303)\n",
      "Epoch 135: Train MSE = 0.0745 (RMSE=0.2730), Val MSE = 0.1009 (RMSE=0.3176)\n",
      "Epoch 136: Train MSE = 0.0745 (RMSE=0.2729), Val MSE = 0.0997 (RMSE=0.3157)\n",
      "Epoch 137: Train MSE = 0.0715 (RMSE=0.2674), Val MSE = 0.1102 (RMSE=0.3320)\n",
      "Epoch 138: Train MSE = 0.0729 (RMSE=0.2701), Val MSE = 0.1022 (RMSE=0.3197)\n",
      "Epoch 139: Train MSE = 0.0787 (RMSE=0.2805), Val MSE = 0.0988 (RMSE=0.3143)\n",
      "Epoch 140: Train MSE = 0.0702 (RMSE=0.2649), Val MSE = 0.0969 (RMSE=0.3113)\n",
      "Epoch 141: Train MSE = 0.0680 (RMSE=0.2608), Val MSE = 0.1022 (RMSE=0.3197)\n",
      "Epoch 142: Train MSE = 0.0650 (RMSE=0.2549), Val MSE = 0.0907 (RMSE=0.3011)\n",
      "Epoch 143: Train MSE = 0.0646 (RMSE=0.2542), Val MSE = 0.0865 (RMSE=0.2942)\n",
      "Epoch 144: Train MSE = 0.0627 (RMSE=0.2505), Val MSE = 0.1012 (RMSE=0.3182)\n",
      "Epoch 145: Train MSE = 0.0639 (RMSE=0.2527), Val MSE = 0.0871 (RMSE=0.2952)\n",
      "Epoch 146: Train MSE = 0.0648 (RMSE=0.2545), Val MSE = 0.0925 (RMSE=0.3042)\n",
      "Epoch 147: Train MSE = 0.0596 (RMSE=0.2442), Val MSE = 0.0818 (RMSE=0.2859)\n",
      "Epoch 148: Train MSE = 0.0566 (RMSE=0.2378), Val MSE = 0.0931 (RMSE=0.3051)\n",
      "Epoch 149: Train MSE = 0.0571 (RMSE=0.2389), Val MSE = 0.0925 (RMSE=0.3041)\n",
      "Epoch 150: Train MSE = 0.0562 (RMSE=0.2370), Val MSE = 0.0810 (RMSE=0.2846)\n",
      "Epoch 151: Train MSE = 0.0566 (RMSE=0.2378), Val MSE = 0.0890 (RMSE=0.2984)\n",
      "Epoch 152: Train MSE = 0.0545 (RMSE=0.2335), Val MSE = 0.0901 (RMSE=0.3002)\n",
      "Epoch 153: Train MSE = 0.0532 (RMSE=0.2307), Val MSE = 0.0826 (RMSE=0.2873)\n",
      "Epoch 154: Train MSE = 0.0533 (RMSE=0.2310), Val MSE = 0.0828 (RMSE=0.2878)\n",
      "Epoch 155: Train MSE = 0.0547 (RMSE=0.2339), Val MSE = 0.0841 (RMSE=0.2900)\n",
      "Epoch 156: Train MSE = 0.0491 (RMSE=0.2215), Val MSE = 0.0828 (RMSE=0.2877)\n",
      "Epoch 157: Train MSE = 0.0505 (RMSE=0.2246), Val MSE = 0.0808 (RMSE=0.2842)\n",
      "Epoch 158: Train MSE = 0.0505 (RMSE=0.2247), Val MSE = 0.0870 (RMSE=0.2949)\n",
      "Epoch 159: Train MSE = 0.0503 (RMSE=0.2243), Val MSE = 0.0799 (RMSE=0.2826)\n",
      "Epoch 160: Train MSE = 0.0493 (RMSE=0.2219), Val MSE = 0.0850 (RMSE=0.2915)\n",
      "Epoch 161: Train MSE = 0.0499 (RMSE=0.2234), Val MSE = 0.0801 (RMSE=0.2831)\n",
      "Epoch 162: Train MSE = 0.0522 (RMSE=0.2284), Val MSE = 0.0776 (RMSE=0.2786)\n",
      "Epoch 163: Train MSE = 0.0493 (RMSE=0.2220), Val MSE = 0.0881 (RMSE=0.2967)\n",
      "Epoch 164: Train MSE = 0.0506 (RMSE=0.2249), Val MSE = 0.0826 (RMSE=0.2875)\n",
      "Epoch 165: Train MSE = 0.0498 (RMSE=0.2232), Val MSE = 0.0787 (RMSE=0.2805)\n",
      "Epoch 166: Train MSE = 0.0464 (RMSE=0.2155), Val MSE = 0.0796 (RMSE=0.2822)\n",
      "Epoch 167: Train MSE = 0.0455 (RMSE=0.2132), Val MSE = 0.0692 (RMSE=0.2631)\n",
      "Epoch 168: Train MSE = 0.0445 (RMSE=0.2109), Val MSE = 0.0670 (RMSE=0.2589)\n",
      "Epoch 169: Train MSE = 0.0422 (RMSE=0.2055), Val MSE = 0.0728 (RMSE=0.2698)\n",
      "Epoch 170: Train MSE = 0.0409 (RMSE=0.2023), Val MSE = 0.0817 (RMSE=0.2858)\n",
      "Epoch 171: Train MSE = 0.0417 (RMSE=0.2043), Val MSE = 0.0722 (RMSE=0.2686)\n",
      "Epoch 172: Train MSE = 0.0380 (RMSE=0.1950), Val MSE = 0.0712 (RMSE=0.2669)\n",
      "Epoch 173: Train MSE = 0.0412 (RMSE=0.2029), Val MSE = 0.0730 (RMSE=0.2702)\n",
      "Epoch 174: Train MSE = 0.0385 (RMSE=0.1962), Val MSE = 0.0739 (RMSE=0.2718)\n",
      "Epoch 175: Train MSE = 0.0376 (RMSE=0.1940), Val MSE = 0.0677 (RMSE=0.2603)\n",
      "Epoch 176: Train MSE = 0.0392 (RMSE=0.1979), Val MSE = 0.0725 (RMSE=0.2693)\n",
      "Epoch 177: Train MSE = 0.0400 (RMSE=0.2001), Val MSE = 0.0715 (RMSE=0.2674)\n",
      "Epoch 178: Train MSE = 0.0382 (RMSE=0.1955), Val MSE = 0.0719 (RMSE=0.2681)\n",
      "Early stopping triggered.\n",
      "Wine Results: {'best_epoch': 168, 'best_val_loss': 0.06704893708229065}\n"
     ]
    }
   ],
   "source": [
    "# wine dataset\n",
    "data_loaders, n_cont, cat_cardinalities, d_out, task_type = prepare_data(\"wine\", batch_size=256)\n",
    "model = build_model(n_cont, cat_cardinalities, d_out)\n",
    "results = train_model(model, data_loaders[\"train\"], data_loaders[\"val\"], task_type, d_out, n_epochs=200, batch_size=256, patience=10, lr=3e-4)\n",
    "print(\"Wine Results:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da0e90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: Train Loss = 0.5127, Train Acc = 0.7833, Val Loss = 0.3634, Val Acc = 0.8482\n",
      "Epoch 002: Train Loss = 0.3593, Train Acc = 0.8500, Val Loss = 0.2823, Val Acc = 0.8837\n",
      "Epoch 003: Train Loss = 0.3061, Train Acc = 0.8731, Val Loss = 0.2454, Val Acc = 0.8989\n",
      "Epoch 004: Train Loss = 0.2756, Train Acc = 0.8861, Val Loss = 0.2247, Val Acc = 0.9078\n",
      "Epoch 005: Train Loss = 0.2542, Train Acc = 0.8950, Val Loss = 0.2087, Val Acc = 0.9144\n",
      "Epoch 006: Train Loss = 0.2390, Train Acc = 0.9012, Val Loss = 0.1921, Val Acc = 0.9204\n",
      "Epoch 007: Train Loss = 0.2268, Train Acc = 0.9068, Val Loss = 0.1902, Val Acc = 0.9213\n",
      "Epoch 008: Train Loss = 0.2163, Train Acc = 0.9108, Val Loss = 0.1756, Val Acc = 0.9282\n",
      "Epoch 009: Train Loss = 0.2082, Train Acc = 0.9140, Val Loss = 0.1704, Val Acc = 0.9301\n",
      "Epoch 010: Train Loss = 0.2016, Train Acc = 0.9165, Val Loss = 0.1662, Val Acc = 0.9319\n",
      "Epoch 011: Train Loss = 0.1951, Train Acc = 0.9197, Val Loss = 0.1544, Val Acc = 0.9368\n",
      "Epoch 012: Train Loss = 0.1889, Train Acc = 0.9222, Val Loss = 0.1548, Val Acc = 0.9369\n",
      "Epoch 013: Train Loss = 0.1835, Train Acc = 0.9242, Val Loss = 0.1474, Val Acc = 0.9398\n",
      "Epoch 014: Train Loss = 0.1785, Train Acc = 0.9259, Val Loss = 0.1483, Val Acc = 0.9388\n",
      "Epoch 015: Train Loss = 0.1744, Train Acc = 0.9282, Val Loss = 0.1438, Val Acc = 0.9409\n",
      "Epoch 016: Train Loss = 0.1707, Train Acc = 0.9295, Val Loss = 0.1358, Val Acc = 0.9448\n",
      "Epoch 017: Train Loss = 0.1679, Train Acc = 0.9309, Val Loss = 0.1343, Val Acc = 0.9445\n",
      "Epoch 018: Train Loss = 0.1648, Train Acc = 0.9320, Val Loss = 0.1306, Val Acc = 0.9464\n",
      "Epoch 019: Train Loss = 0.1606, Train Acc = 0.9337, Val Loss = 0.1383, Val Acc = 0.9433\n",
      "Epoch 020: Train Loss = 0.1573, Train Acc = 0.9350, Val Loss = 0.1321, Val Acc = 0.9449\n",
      "Epoch 021: Train Loss = 0.1547, Train Acc = 0.9360, Val Loss = 0.1247, Val Acc = 0.9488\n",
      "Epoch 022: Train Loss = 0.1518, Train Acc = 0.9373, Val Loss = 0.1211, Val Acc = 0.9512\n",
      "Epoch 023: Train Loss = 0.1499, Train Acc = 0.9381, Val Loss = 0.1220, Val Acc = 0.9500\n",
      "Epoch 024: Train Loss = 0.1482, Train Acc = 0.9389, Val Loss = 0.1185, Val Acc = 0.9513\n",
      "Epoch 025: Train Loss = 0.1454, Train Acc = 0.9399, Val Loss = 0.1199, Val Acc = 0.9511\n",
      "Epoch 026: Train Loss = 0.1436, Train Acc = 0.9411, Val Loss = 0.1171, Val Acc = 0.9525\n",
      "Epoch 027: Train Loss = 0.1419, Train Acc = 0.9416, Val Loss = 0.1177, Val Acc = 0.9515\n",
      "Epoch 028: Train Loss = 0.1395, Train Acc = 0.9427, Val Loss = 0.1172, Val Acc = 0.9520\n",
      "Epoch 029: Train Loss = 0.1380, Train Acc = 0.9430, Val Loss = 0.1125, Val Acc = 0.9536\n",
      "Epoch 030: Train Loss = 0.1366, Train Acc = 0.9436, Val Loss = 0.1158, Val Acc = 0.9527\n",
      "Epoch 031: Train Loss = 0.1349, Train Acc = 0.9440, Val Loss = 0.1104, Val Acc = 0.9542\n",
      "Epoch 032: Train Loss = 0.1339, Train Acc = 0.9448, Val Loss = 0.1117, Val Acc = 0.9555\n",
      "Epoch 033: Train Loss = 0.1326, Train Acc = 0.9455, Val Loss = 0.1112, Val Acc = 0.9549\n",
      "Epoch 034: Train Loss = 0.1303, Train Acc = 0.9463, Val Loss = 0.1093, Val Acc = 0.9552\n",
      "Epoch 035: Train Loss = 0.1284, Train Acc = 0.9471, Val Loss = 0.1083, Val Acc = 0.9553\n",
      "Epoch 036: Train Loss = 0.1276, Train Acc = 0.9474, Val Loss = 0.1075, Val Acc = 0.9562\n",
      "Epoch 037: Train Loss = 0.1270, Train Acc = 0.9478, Val Loss = 0.1054, Val Acc = 0.9564\n",
      "Epoch 038: Train Loss = 0.1250, Train Acc = 0.9485, Val Loss = 0.1045, Val Acc = 0.9566\n",
      "Epoch 039: Train Loss = 0.1234, Train Acc = 0.9490, Val Loss = 0.1042, Val Acc = 0.9582\n",
      "Epoch 040: Train Loss = 0.1231, Train Acc = 0.9492, Val Loss = 0.1010, Val Acc = 0.9585\n",
      "Epoch 041: Train Loss = 0.1216, Train Acc = 0.9497, Val Loss = 0.1010, Val Acc = 0.9584\n",
      "Epoch 042: Train Loss = 0.1207, Train Acc = 0.9508, Val Loss = 0.1059, Val Acc = 0.9570\n",
      "Epoch 043: Train Loss = 0.1195, Train Acc = 0.9507, Val Loss = 0.1035, Val Acc = 0.9581\n",
      "Epoch 044: Train Loss = 0.1180, Train Acc = 0.9514, Val Loss = 0.1006, Val Acc = 0.9585\n",
      "Epoch 045: Train Loss = 0.1185, Train Acc = 0.9513, Val Loss = 0.1008, Val Acc = 0.9576\n",
      "Epoch 046: Train Loss = 0.1159, Train Acc = 0.9526, Val Loss = 0.0997, Val Acc = 0.9591\n",
      "Epoch 047: Train Loss = 0.1157, Train Acc = 0.9526, Val Loss = 0.1044, Val Acc = 0.9583\n",
      "Epoch 048: Train Loss = 0.1148, Train Acc = 0.9528, Val Loss = 0.1034, Val Acc = 0.9578\n",
      "Epoch 049: Train Loss = 0.1142, Train Acc = 0.9527, Val Loss = 0.0957, Val Acc = 0.9606\n",
      "Epoch 050: Train Loss = 0.1124, Train Acc = 0.9540, Val Loss = 0.0971, Val Acc = 0.9609\n",
      "Epoch 051: Train Loss = 0.1118, Train Acc = 0.9541, Val Loss = 0.0976, Val Acc = 0.9610\n",
      "Epoch 052: Train Loss = 0.1107, Train Acc = 0.9543, Val Loss = 0.0935, Val Acc = 0.9619\n",
      "Epoch 053: Train Loss = 0.1104, Train Acc = 0.9543, Val Loss = 0.0952, Val Acc = 0.9618\n",
      "Epoch 054: Train Loss = 0.1096, Train Acc = 0.9549, Val Loss = 0.0967, Val Acc = 0.9608\n",
      "Epoch 055: Train Loss = 0.1088, Train Acc = 0.9553, Val Loss = 0.0995, Val Acc = 0.9595\n",
      "Epoch 056: Train Loss = 0.1082, Train Acc = 0.9554, Val Loss = 0.0957, Val Acc = 0.9610\n",
      "Epoch 057: Train Loss = 0.1072, Train Acc = 0.9559, Val Loss = 0.0952, Val Acc = 0.9611\n",
      "Epoch 058: Train Loss = 0.1062, Train Acc = 0.9564, Val Loss = 0.0944, Val Acc = 0.9615\n",
      "Epoch 059: Train Loss = 0.1062, Train Acc = 0.9564, Val Loss = 0.0947, Val Acc = 0.9618\n",
      "Epoch 060: Train Loss = 0.1050, Train Acc = 0.9566, Val Loss = 0.0931, Val Acc = 0.9625\n",
      "Epoch 061: Train Loss = 0.1049, Train Acc = 0.9567, Val Loss = 0.0911, Val Acc = 0.9626\n",
      "Epoch 062: Train Loss = 0.1038, Train Acc = 0.9570, Val Loss = 0.0954, Val Acc = 0.9614\n",
      "Epoch 063: Train Loss = 0.1034, Train Acc = 0.9576, Val Loss = 0.0887, Val Acc = 0.9641\n",
      "Epoch 064: Train Loss = 0.1030, Train Acc = 0.9577, Val Loss = 0.0912, Val Acc = 0.9634\n",
      "Epoch 065: Train Loss = 0.1012, Train Acc = 0.9584, Val Loss = 0.0913, Val Acc = 0.9633\n",
      "Epoch 066: Train Loss = 0.1018, Train Acc = 0.9583, Val Loss = 0.0916, Val Acc = 0.9627\n",
      "Epoch 067: Train Loss = 0.1006, Train Acc = 0.9587, Val Loss = 0.0940, Val Acc = 0.9626\n",
      "Epoch 068: Train Loss = 0.1004, Train Acc = 0.9587, Val Loss = 0.0913, Val Acc = 0.9631\n",
      "Epoch 069: Train Loss = 0.0999, Train Acc = 0.9588, Val Loss = 0.0871, Val Acc = 0.9652\n",
      "Epoch 070: Train Loss = 0.0988, Train Acc = 0.9592, Val Loss = 0.0887, Val Acc = 0.9642\n",
      "Epoch 071: Train Loss = 0.0984, Train Acc = 0.9597, Val Loss = 0.0884, Val Acc = 0.9645\n",
      "Epoch 072: Train Loss = 0.0984, Train Acc = 0.9595, Val Loss = 0.0912, Val Acc = 0.9629\n",
      "Epoch 073: Train Loss = 0.0974, Train Acc = 0.9598, Val Loss = 0.0898, Val Acc = 0.9643\n",
      "Epoch 074: Train Loss = 0.0970, Train Acc = 0.9603, Val Loss = 0.0890, Val Acc = 0.9643\n",
      "Epoch 075: Train Loss = 0.0964, Train Acc = 0.9605, Val Loss = 0.0891, Val Acc = 0.9641\n",
      "Epoch 076: Train Loss = 0.0962, Train Acc = 0.9605, Val Loss = 0.0859, Val Acc = 0.9653\n",
      "Epoch 077: Train Loss = 0.0951, Train Acc = 0.9608, Val Loss = 0.0843, Val Acc = 0.9659\n",
      "Epoch 078: Train Loss = 0.0948, Train Acc = 0.9610, Val Loss = 0.0894, Val Acc = 0.9640\n",
      "Epoch 079: Train Loss = 0.0945, Train Acc = 0.9612, Val Loss = 0.0865, Val Acc = 0.9652\n",
      "Epoch 080: Train Loss = 0.0939, Train Acc = 0.9613, Val Loss = 0.0843, Val Acc = 0.9662\n",
      "Epoch 081: Train Loss = 0.0928, Train Acc = 0.9620, Val Loss = 0.0863, Val Acc = 0.9655\n",
      "Epoch 082: Train Loss = 0.0930, Train Acc = 0.9617, Val Loss = 0.0863, Val Acc = 0.9651\n",
      "Epoch 083: Train Loss = 0.0925, Train Acc = 0.9618, Val Loss = 0.0856, Val Acc = 0.9664\n",
      "Epoch 084: Train Loss = 0.0924, Train Acc = 0.9621, Val Loss = 0.0852, Val Acc = 0.9656\n",
      "Epoch 085: Train Loss = 0.0916, Train Acc = 0.9623, Val Loss = 0.0880, Val Acc = 0.9645\n",
      "Epoch 086: Train Loss = 0.0916, Train Acc = 0.9626, Val Loss = 0.0860, Val Acc = 0.9655\n",
      "Epoch 087: Train Loss = 0.0907, Train Acc = 0.9629, Val Loss = 0.0826, Val Acc = 0.9668\n",
      "Epoch 088: Train Loss = 0.0905, Train Acc = 0.9627, Val Loss = 0.0870, Val Acc = 0.9653\n",
      "Epoch 089: Train Loss = 0.0903, Train Acc = 0.9629, Val Loss = 0.0880, Val Acc = 0.9652\n",
      "Epoch 090: Train Loss = 0.0899, Train Acc = 0.9632, Val Loss = 0.0853, Val Acc = 0.9661\n",
      "Epoch 091: Train Loss = 0.0889, Train Acc = 0.9634, Val Loss = 0.0839, Val Acc = 0.9668\n",
      "Epoch 092: Train Loss = 0.0888, Train Acc = 0.9635, Val Loss = 0.0862, Val Acc = 0.9655\n",
      "Epoch 093: Train Loss = 0.0886, Train Acc = 0.9637, Val Loss = 0.0848, Val Acc = 0.9664\n",
      "Epoch 094: Train Loss = 0.0888, Train Acc = 0.9636, Val Loss = 0.0839, Val Acc = 0.9669\n",
      "Epoch 095: Train Loss = 0.0883, Train Acc = 0.9634, Val Loss = 0.0843, Val Acc = 0.9663\n",
      "Epoch 096: Train Loss = 0.0870, Train Acc = 0.9643, Val Loss = 0.0874, Val Acc = 0.9657\n",
      "Epoch 097: Train Loss = 0.0870, Train Acc = 0.9643, Val Loss = 0.0891, Val Acc = 0.9647\n",
      "Epoch 098: Train Loss = 0.0857, Train Acc = 0.9648, Val Loss = 0.0871, Val Acc = 0.9653\n",
      "Epoch 099: Train Loss = 0.0872, Train Acc = 0.9642, Val Loss = 0.0899, Val Acc = 0.9642\n",
      "Epoch 100: Train Loss = 0.0858, Train Acc = 0.9646, Val Loss = 0.0862, Val Acc = 0.9657\n",
      "Covtype Results: {'best_epoch': 94, 'best_val_acc': 0.9669371702968081}\n"
     ]
    }
   ],
   "source": [
    "# covtype dataset\n",
    "data_loaders, n_cont, cat_cardinalities, d_out, task_type = prepare_data(\"covtype\", batch_size=256)\n",
    "model = build_model(n_cont, cat_cardinalities, d_out)\n",
    "results = train_model(model, data_loaders[\"train\"], data_loaders[\"val\"], task_type, d_out, n_epochs=100, batch_size=256, patience=10, lr=3e-4)\n",
    "print(\"Covtype Results:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b8cfec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary classification\n",
      "(32950, 20) (32950,)\n",
      "(8238, 20) (8238,)\n",
      "Epoch 001: Train Loss = 0.2292, Train Acc = 0.8971, Val Loss = 0.1893, Val Acc = 0.9124\n",
      "Epoch 002: Train Loss = 0.1897, Train Acc = 0.9090, Val Loss = 0.1840, Val Acc = 0.9182\n",
      "Epoch 003: Train Loss = 0.1851, Train Acc = 0.9109, Val Loss = 0.1815, Val Acc = 0.9198\n",
      "Epoch 004: Train Loss = 0.1832, Train Acc = 0.9132, Val Loss = 0.1783, Val Acc = 0.9193\n",
      "Epoch 005: Train Loss = 0.1810, Train Acc = 0.9135, Val Loss = 0.1756, Val Acc = 0.9207\n",
      "Epoch 006: Train Loss = 0.1792, Train Acc = 0.9143, Val Loss = 0.1743, Val Acc = 0.9212\n",
      "Epoch 007: Train Loss = 0.1780, Train Acc = 0.9149, Val Loss = 0.1784, Val Acc = 0.9202\n",
      "Epoch 008: Train Loss = 0.1771, Train Acc = 0.9158, Val Loss = 0.1727, Val Acc = 0.9216\n",
      "Epoch 009: Train Loss = 0.1756, Train Acc = 0.9162, Val Loss = 0.1757, Val Acc = 0.9216\n",
      "Epoch 010: Train Loss = 0.1757, Train Acc = 0.9167, Val Loss = 0.1726, Val Acc = 0.9210\n",
      "Epoch 011: Train Loss = 0.1742, Train Acc = 0.9173, Val Loss = 0.1747, Val Acc = 0.9226\n",
      "Epoch 012: Train Loss = 0.1742, Train Acc = 0.9171, Val Loss = 0.1730, Val Acc = 0.9224\n",
      "Epoch 013: Train Loss = 0.1729, Train Acc = 0.9176, Val Loss = 0.1718, Val Acc = 0.9206\n",
      "Epoch 014: Train Loss = 0.1725, Train Acc = 0.9171, Val Loss = 0.1738, Val Acc = 0.9213\n",
      "Epoch 015: Train Loss = 0.1716, Train Acc = 0.9179, Val Loss = 0.1745, Val Acc = 0.9206\n",
      "Epoch 016: Train Loss = 0.1710, Train Acc = 0.9187, Val Loss = 0.1728, Val Acc = 0.9223\n",
      "Epoch 017: Train Loss = 0.1699, Train Acc = 0.9181, Val Loss = 0.1775, Val Acc = 0.9162\n",
      "Epoch 018: Train Loss = 0.1695, Train Acc = 0.9188, Val Loss = 0.1754, Val Acc = 0.9205\n",
      "Epoch 019: Train Loss = 0.1693, Train Acc = 0.9180, Val Loss = 0.1748, Val Acc = 0.9215\n",
      "Epoch 020: Train Loss = 0.1678, Train Acc = 0.9188, Val Loss = 0.1748, Val Acc = 0.9201\n",
      "Epoch 021: Train Loss = 0.1672, Train Acc = 0.9198, Val Loss = 0.1754, Val Acc = 0.9204\n",
      "Early stopping triggered.\n",
      "Bank Results: {'best_epoch': 11, 'best_val_acc': 0.9225540179655256}\n"
     ]
    }
   ],
   "source": [
    "# bank dataset\n",
    "data_loaders, n_cont, cat_cardinalities, d_out, task_type = prepare_data(\"bank\", batch_size=256)\n",
    "model = build_model(n_cont, cat_cardinalities, d_out)\n",
    "results = train_model(model, data_loaders[\"train\"], data_loaders[\"val\"], task_type, d_out, n_epochs=100, batch_size=256, patience=10, lr=3e-4)\n",
    "print(\"Bank Results:\", results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "YOLO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
